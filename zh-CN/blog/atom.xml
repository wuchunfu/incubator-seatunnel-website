<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://seatunnel.apache.org/zh-CN/blog</id>
    <title>Apache SeaTunnel Blog</title>
    <updated>2021-12-30T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://seatunnel.apache.org/zh-CN/blog"/>
    <subtitle>Apache SeaTunnel Blog</subtitle>
    <icon>https://seatunnel.apache.org/zh-CN/image/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[如何快速地把 HDFS 中的数据导入 ClickHouse]]></title>
        <id>hdfs-to-clickhouse</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/hdfs-to-clickhouse"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[ClickHouse 是面向 OLAP 的分布式列式 DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至 ClickHouse 这个优秀的数据仓库之中，当前日数据量达到了 300 亿。]]></summary>
        <content type="html"><![CDATA[<p>ClickHouse 是面向 OLAP 的分布式列式 DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至 ClickHouse 这个优秀的数据仓库之中，当前日数据量达到了 300 亿。</p><p>之前介绍的有关数据处理入库的经验都是基于实时数据流，数据存储在 Kafka 中，我们使用 Java 或者 Golang 将数据从 Kafka 中读取、解析、清洗之后写入 ClickHouse 中，这样可以实现数据的快速接入。然而在很多同学的使用场景中，数据都不是实时的，可能需要将 HDFS 或者是 Hive 中的数据导入 ClickHouse。有的同学通过编写 Spark 程序来实现数据的导入，那么是否有更简单、高效的方法呢。</p><p>目前开源社区上有一款工具 <strong>Seatunnel</strong>，项目地址 <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a>，可以快速地将 HDFS 中的数据导入 ClickHouse。</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="hdfs-to-clickhouse">HDFS To ClickHouse<a class="hash-link" href="#hdfs-to-clickhouse" title="Direct link to heading">​</a></h2><p>假设我们的日志存储在 HDFS 中，我们需要将日志进行解析并筛选出我们关心的字段，将对应的字段写入 ClickHouse 的表中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="log-sample">Log Sample<a class="hash-link" href="#log-sample" title="Direct link to heading">​</a></h3><p>我们在 HDFS 中存储的日志格式如下， 是很常见的 Nginx 日志</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token number">10.41</span><span class="token plain">.1.28 github.com </span><span class="token number">114.250</span><span class="token plain">.140.241 </span><span class="token number">0</span><span class="token plain">.001s </span><span class="token string" style="color:rgb(255, 121, 198)">"127.0.0.1:80"</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">26</span><span class="token plain">/Oct/2018:03:09:32 +0800</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"GET /Apache/Seatunnel HTTP/1.1"</span><span class="token plain"> </span><span class="token number">200</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"-"</span><span class="token plain"> - </span><span class="token string" style="color:rgb(255, 121, 198)">"Dalvik/2.1.0 (Linux; U; Android 7.1.1; OPPO R11 Build/NMF26X)"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"196"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"-"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"mainpage"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"443"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"-"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"172.16.181.129"</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="clickhouse-schema">ClickHouse Schema<a class="hash-link" href="#clickhouse-schema" title="Direct link to heading">​</a></h3><p>我们的 ClickHouse 建表语句如下，我们的表按日进行分区</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE cms.cms_msg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> Date, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    datetime DateTime, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    request_time Float32, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">hostname</span><span class="token plain"> String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remote_addr String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    data_size Int32, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    pool String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ENGINE </span><span class="token operator">=</span><span class="token plain"> MergeTree PARTITION BY </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> ORDER BY </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> SETTINGS index_granularity </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">16384</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-with-clickhouse">Seatunnel with ClickHouse<a class="hash-link" href="#seatunnel-with-clickhouse" title="Direct link to heading">​</a></h2><p>接下来会给大家详细介绍，我们如何通过 Seatunnel 满足上述需求，将 HDFS 中的数据写入 ClickHouse 中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上。Seatunnel 拥有着非常丰富的插件，支持从 Kafka、HDFS、Kudu 中读取数据，进行各种各样的数据处理，并将结果写入 ClickHouse、Elasticsearch 或者 Kafka 中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="prerequisites">Prerequisites<a class="hash-link" href="#prerequisites" title="Direct link to heading">​</a></h3><p>首先我们需要安装 Seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备 Spark 环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">wget</span><span class="token plain"> https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">tar</span><span class="token plain"> -xvf https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">wget</span><span class="token plain"> https://github.com/InterestingLab/seatunnel/releases/download/v1.1.1/seatunnel-1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">unzip</span><span class="token plain"> seatunnel-1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> seatunnel-1.1.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">vim</span><span class="token plain"> config/seatunnel-env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># 指定Spark安装路径</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">SPARK_HOME</span><span class="token operator">=</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">${SPARK_HOME</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">:-</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">/</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">usr</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">/</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">local</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">/</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">spark-2.2.0-bin-hadoop2.7}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个 seatunnel Pipeline 的配置文件即可完成数据的导入。</p><p>配置文件包括四个部分，分别是 Spark、Input、filter 和 Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是 Spark 的相关配置，主要配置 Spark 执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"1g"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>这一部分定义数据源，如下是从 HDFS 文件中读取 text 格式数据的配置案例。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">input </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hdfs </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        path </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"hdfs://nomanode:8020/rowlog/accesslog"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">format</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"text"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>在 Filter 部分，这里我们配置一系列的转化，包括正则解析将日志进行拆分、时间转换将 HTTPDATE 转化为 ClickHouse 支持的日期格式、对 Number 类型的字段进行类型转换以及通过 SQL 进行字段筛减等</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用正则解析原始日志</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"raw_message"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'%{IP:ha_ip}\\s%{NOTSPACE:domain}\\s%{IP:remote_addr}\\s%{NUMBER:request_time}s\\s\"%{DATA:upstream_ip}\"\\s\\[%{HTTPDATE:timestamp}\\]\\s\"%{NOTSPACE:method}\\s%{DATA:url}\\s%{NOTSPACE:http_ver}\"\\s%{NUMBER:status}\\s%{NUMBER:body_bytes_send}\\s%{DATA:referer}\\s%{NOTSPACE:cookie_info}\\s\"%{DATA:user_agent}\"\\s%{DATA:uid}\\s%{DATA:session_id}\\s\"%{DATA:pool}\"\\s\"%{DATA:tag2}\"\\s%{DATA:tag3}\\s%{DATA:tag4}'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># "yyyy/MM/dd HH:mm:ss"格式的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"timestamp"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"dd/MMM/yyyy:HH:mm:ss Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"yyyy/MM/dd HH:mm:ss"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用SQL筛选关注的字段，并对字段进行处理</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 甚至可以通过过滤条件过滤掉不关心的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"select substring(date, 1, 10) as date, datetime, hostname, url, http_code, float(request_time), int(data_size), domain from access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>最后我们将处理好的结构化数据写入 ClickHouse</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">host</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"your.clickhouse.host:8123"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"date"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"hostname"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"uri"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"http_code"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"request_time"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"data_size"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"domain"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"username"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"password"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="running-seatunnel">Running seatunnel<a class="hash-link" href="#running-seatunnel" title="Direct link to heading">​</a></h3><p>我们将上述四部分配置组合成为我们的配置文件 <code>config/batch.conf</code>。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">vim</span><span class="token plain"> config/batch.conf</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"1g"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hdfs </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        path </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"hdfs://nomanode:8020/rowlog/accesslog"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">format</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"text"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用正则解析原始日志</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"raw_message"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'%{IP:ha_ip}\\s%{NOTSPACE:domain}\\s%{IP:remote_addr}\\s%{NUMBER:request_time}s\\s\"%{DATA:upstream_ip}\"\\s\\[%{HTTPDATE:timestamp}\\]\\s\"%{NOTSPACE:method}\\s%{DATA:url}\\s%{NOTSPACE:http_ver}\"\\s%{NUMBER:status}\\s%{NUMBER:body_bytes_send}\\s%{DATA:referer}\\s%{NOTSPACE:cookie_info}\\s\"%{DATA:user_agent}\"\\s%{DATA:uid}\\s%{DATA:session_id}\\s\"%{DATA:pool}\"\\s\"%{DATA:tag2}\"\\s%{DATA:tag3}\\s%{DATA:tag4}'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># "yyyy/MM/dd HH:mm:ss"格式的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"timestamp"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"dd/MMM/yyyy:HH:mm:ss Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"yyyy/MM/dd HH:mm:ss"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用SQL筛选关注的字段，并对字段进行处理</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 甚至可以通过过滤条件过滤掉不关心的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"select substring(date, 1, 10) as date, datetime, hostname, url, http_code, float(request_time), int(data_size), domain from access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">host</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"your.clickhouse.host:8123"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"date"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"hostname"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"uri"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"http_code"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"request_time"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"data_size"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"domain"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"username"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"password"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel，即可将数据写入 ClickHouse。这里我们以本地模式为例。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/start-seatunnel.sh --config config/batch.conf -e client -m </span><span class="token string" style="color:rgb(255, 121, 198)">'local[2]'</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何使用 Seatunnel 将 HDFS 中的 Nginx 日志文件导入 ClickHouse 中。仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码。除了支持 HDFS 数据源之外，Seatunnel 同样支持将数据从 Kafka 中实时读取处理写入 ClickHouse 中。我们的下一篇文章将会介绍，如何将 Hive 中的数据快速导入 ClickHouse 中。</p><p>当然，Seatunnel 不仅仅是 ClickHouse 数据写入的工具，在 Elasticsearch 以及 Kafka等 数据源的写入上同样可以扮演相当重要的角色。</p><p>希望了解 Seatunnel 和 ClickHouse、Elasticsearch、Kafka 结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><p>-- Power by <a href="https://github.com/InterestingLab" target="_blank" rel="noopener noreferrer">InterestingLab</a></p>]]></content>
        <category label="HDFS" term="HDFS"/>
        <category label="ClickHouse" term="ClickHouse"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何快速地把 Hive 中的数据导入 ClickHouse]]></title>
        <id>hive-to-clickhouse</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/hive-to-clickhouse"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[ClickHouse是面向OLAP的分布式列式DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至ClickHouse这个优秀的数据仓库之中，当前日数据量达到了300亿。]]></summary>
        <content type="html"><![CDATA[<p>ClickHouse是面向OLAP的分布式列式DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至ClickHouse这个优秀的数据仓库之中，当前日数据量达到了300亿。</p><p>在之前的文章 <a href="/zh-CN/blog/hdfs-to-clickhouse">如何快速地把HDFS中的数据导入ClickHouse</a> 中我们提到过使用 Seatunnel <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> 对HDFS中的数据经过很简单的操作就可以将数据写入ClickHouse。HDFS中的数据一般是非结构化的数据，那么针对存储在Hive中的结构化数据，我们应该怎么操作呢？</p><p><img src="/zh-CN/assets/images/hive-logo-c9aedd90b5ea9668c87fe25ad92a8e6c.png" width="962" height="518"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="hive-to-clickhouse">Hive to ClickHouse<a class="hash-link" href="#hive-to-clickhouse" title="Direct link to heading">​</a></h2><p>假定我们的数据已经存储在Hive中，我们需要读取Hive表中的数据并筛选出我们关心的字段，或者对字段进行转换，最后将对应的字段写入ClickHouse的表中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="hive-schema">Hive Schema<a class="hash-link" href="#hive-schema" title="Direct link to heading">​</a></h3><p>我们在Hive中存储的数据表结构如下，存储的是很常见的Nginx日志</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE `nginx_msg_detail`(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `hostname` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `domain` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `remote_addr` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `request_time` float,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `datetime` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `url` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `status` int,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `data_size` int,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `referer` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `cookie_info` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `user_agent` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `minute` string)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> PARTITIONED BY (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `date` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `hour` string)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="clickhouse-schema">ClickHouse Schema<a class="hash-link" href="#clickhouse-schema" title="Direct link to heading">​</a></h3><p>我们的ClickHouse建表语句如下，我们的表按日进行分区</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE cms.cms_msg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date Date,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    datetime DateTime,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    request_time Float32,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hostname String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remote_addr String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    data_size Int32</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) ENGINE = MergeTree PARTITION BY date ORDER BY (date, hostname) SETTINGS index_granularity = 16384</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-with-clickhouse">Seatunnel with ClickHouse<a class="hash-link" href="#seatunnel-with-clickhouse" title="Direct link to heading">​</a></h2><p>接下来会给大家介绍，我们如何通过 Seatunnel 将Hive中的数据写入ClickHouse中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上。Seatunnel 拥有着非常丰富的插件，支持从Kafka、HDFS、Kudu中读取数据，进行各种各样的数据处理，并将结果写入ClickHouse、Elasticsearch或者Kafka中。</p><p>Seatunnel的环境准备以及安装步骤这里就不一一赘述了，具体安装步骤可以参考上一篇文章或者访问 <a href="/zh-CN/docs/introduction">Seatunnel Docs</a></p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">Seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个Seatunnel Pipeline的配置文件即可完成数据的导入。</p><p>配置文件包括四个部分，分别是Spark、Input、filter和Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是Spark的相关配置，主要配置Spark执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  // 这个配置必需填写</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.sql.catalogImplementation = "hive"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>这一部分定义数据源，如下是从Hive文件中读取text格式数据的配置案例。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hive {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from access.nginx_msg_detail"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>看，很简单的一个配置就可以从Hive中读取数据了。其中<code>pre_sql</code>是从Hive中读取数据SQL，<code>table_name</code>是将读取后的数据，注册成为Spark中临时表的表名，可为任意字段。</p><p>需要注意的是，必须保证hive的metastore是在服务状态。</p><p>在Cluster、Client、Local模式下运行时，必须把<code>hive-site.xml</code>文件置于提交任务节点的$HADOOP_CONF目录下</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>在Filter部分，这里我们配置一系列的转化，我们这里把不需要的minute和hour字段丢弃。当然我们也可以在读取Hive的时候通过<code>pre_sql</code>不读取这些字段</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remove {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = ["minute", "hour"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>最后我们将处理好的结构化数据写入ClickHouse</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        host = "your.clickhouse.host:8123"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "nginx_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields = ["date", "datetime", "hostname", "url", "http_code", "request_time", "data_size", "domain"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="running-seatunnel">Running Seatunnel<a class="hash-link" href="#running-seatunnel" title="Direct link to heading">​</a></h3><p>我们将上述四部分配置组合成为我们的配置文件<code>config/batch.conf</code>。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/batch.conf</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  // 这个配置必需填写</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.sql.catalogImplementation = "hive"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hive {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from access.nginx_msg_detail"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remove {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = ["minute", "hour"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        host = "your.clickhouse.host:8123"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields = ["date", "datetime", "hostname", "uri", "http_code", "request_time", "data_size", "domain"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel，即可将数据写入ClickHouse。这里我们以本地模式为例。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/start-seatunnel.sh --config config/batch.conf -e client -m 'local[2]'</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何使用 Seatunnel 将Hive中的数据导入ClickHouse中。仅仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码，十分简单。</p><p>希望了解 Seatunnel 与ClickHouse、Elasticsearch、Kafka、Hadoop结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><p>-- Power by <a href="https://github.com/InterestingLab" target="_blank" rel="noopener noreferrer">InterestingLab</a></p>]]></content>
        <category label="Hive" term="Hive"/>
        <category label="ClickHouse" term="ClickHouse"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何使用 Spark 快速将数据写入 Elasticsearch]]></title>
        <id>spark-execute-elasticsearch</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/spark-execute-elasticsearch"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[说到数据写入 Elasticsearch，最先想到的肯定是Logstash。Logstash因为其简单上手、可扩展、可伸缩等优点被广大用户接受。但是尺有所短，寸有所长，Logstash肯定也有它无法适用的应用场景，比如：]]></summary>
        <content type="html"><![CDATA[<p>说到数据写入 Elasticsearch，最先想到的肯定是Logstash。Logstash因为其简单上手、可扩展、可伸缩等优点被广大用户接受。但是尺有所短，寸有所长，Logstash肯定也有它无法适用的应用场景，比如：</p><ul><li>海量数据ETL</li><li>海量数据聚合</li><li>多源数据处理</li></ul><p>为了满足这些场景，很多同学都会选择Spark，借助Spark算子进行数据处理，最后将处理结果写入Elasticsearch。</p><p>我们部门之前利用Spark对Nginx日志进行分析，统计我们的Web服务访问情况，将Nginx日志每分钟聚合一次最后将结果写入Elasticsearch，然后利用Kibana配置实时监控Dashboard。Elasticsearch和Kibana都很方便、实用，但是随着类似需求越来越多，如何快速通过Spark将数据写入Elasticsearch成为了我们的一大问题。</p><p>今天给大家推荐一款能够实现数据快速写入的黑科技 Seatunnel <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> 一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上，简单易用，灵活配置，无需开发。</p><p><img src="/zh-CN/assets/images/wd-struct-fd963482dc80fdee6e4930107709bd28.png" width="818" height="466"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="kafka-to-elasticsearch">Kafka to Elasticsearch<a class="hash-link" href="#kafka-to-elasticsearch" title="Direct link to heading">​</a></h2><p>和Logstash一样，Seatunnel同样支持多种类型的数据输入，这里我们以最常见的Kakfa作为输入源为例，讲解如何使用 Seatunnel 将数据快速写入Elasticsearch</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="log-sample">Log Sample<a class="hash-link" href="#log-sample" title="Direct link to heading">​</a></h3><p>原始日志格式如下:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">127.0.0.1 elasticsearch.cn 114.250.140.241 0.001s "127.0.0.1:80" [26/Oct/2018:21:54:32 +0800] "GET /article HTTP/1.1" 200 123 "-" - "Dalvik/2.1.0 (Linux; U; Android 7.1.1; OPPO R11 Build/NMF26X)"</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="elasticsearch-document">Elasticsearch Document<a class="hash-link" href="#elasticsearch-document" title="Direct link to heading">​</a></h3><p>我们想要统计，一分钟每个域名的访问情况，聚合完的数据有以下字段:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">domain String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hostname String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">status int</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">datetime String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">count int</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-with-elasticsearch">Seatunnel with Elasticsearch<a class="hash-link" href="#seatunnel-with-elasticsearch" title="Direct link to heading">​</a></h2><p>接下来会给大家详细介绍，我们如何通过 Seatunnel 读取Kafka中的数据，对数据进行解析以及聚合，最后将处理结果写入Elasticsearch中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 同样拥有着非常丰富的插件，支持从Kafka、HDFS、Hive中读取数据，进行各种各样的数据处理，并将结果写入Elasticsearch、Kudu或者Kafka中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="prerequisites">Prerequisites<a class="hash-link" href="#prerequisites" title="Direct link to heading">​</a></h3><p>首先我们需要安装seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备Spark环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT language-yaml theme-code-block"><div class="codeBlockContent_wNvx yaml"><pre tabindex="0" class="prism-code language-yaml codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">//archive.apache.org/dist/spark/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">bin</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tar </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">xvf https</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">//archive.apache.org/dist/spark/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">bin</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">//github.com/InterestingLab/seatunnel/releases/download/v1.1.1/seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">1.1.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># 指定Spark安装路径</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SPARK_HOME=$</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">SPARK_HOME</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">/usr/local/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">bin</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">hadoop2.7</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">Seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>与Logstash一样，我们仅需要编写一个Seatunnel Pipeline的配置文件即可完成数据的导入，相信了解Logstash的朋友可以很快入手 Seatunnel 配置。</p><p>配置文件包括四个部分，分别是Spark、Input、filter和Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是Spark的相关配置，主要配置Spark执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.streaming.batchDuration = 5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>这一部分定义数据源，如下是从Kafka中读取数据的配置案例，</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    topics = "seatunnel-es"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.group.id = "seatunnel_es_group"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.rebalance.max.retries = 100</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>在Filter部分，这里我们配置一系列的转化，包括正则解析将日志进行拆分、时间转换将HTTPDATE转化为Elasticsearch支持的日期格式、对Number类型的字段进行类型转换以及通过SQL进行数据聚合</p><div class="codeBlockContainer_I0IT language-yaml theme-code-block"><div class="codeBlockContent_wNvx yaml"><pre tabindex="0" class="prism-code language-yaml codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用正则解析原始日志</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 最开始数据都在raw_message字段中</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "raw_message"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern = '%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">hostname</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">domain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">IP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">remote_addr</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NUMBER</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">request_time</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">s\\s\"%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">upstream_ip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\"\\s\\</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">HTTPDATE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">timestamp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain">\\s\"%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">method</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">url</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">http_ver</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\"\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NUMBER</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NUMBER</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">body_bytes_send</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">referer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">cookie_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s\"%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">user_agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">'</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Elasticsearch中支持的格式</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "timestamp"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field = "datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format = "dd/MMM/yyyy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">HH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">mm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">ss Z"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format = "yyyy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">MM</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">dd'T'HH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">mm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">ss.SSS+08</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">00"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)">## 利用SQL对数据进行聚合</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select domain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> hostname</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> int(status)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> datetime</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> count(</span><span class="token important">*)</span><span class="token plain"> from access_log group by domain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> hostname</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>最后我们将处理好的结构化数据写入Elasticsearch。</p><div class="codeBlockContainer_I0IT language-yaml theme-code-block"><div class="codeBlockContent_wNvx yaml"><pre tabindex="0" class="prism-code language-yaml codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elasticsearch </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        hosts = </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"localhost:9200"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index = "seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">$</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">now</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        es.batch.size.entries = 100000</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index_time_format = "yyyy.MM.dd"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="running-seatunnel">Running Seatunnel<a class="hash-link" href="#running-seatunnel" title="Direct link to heading">​</a></h3><p>我们将上述四部分配置组合成为我们的配置文件 <code>config/batch.conf</code>。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/batch.conf</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.streaming.batchDuration = 5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "seatunnel-es"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.group.id = "seatunnel_es_group"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.rebalance.max.retries = 100</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 使用正则解析原始日志</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 最开始数据都在raw_message字段中</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "raw_message"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern = '%{IP:hostname}\\s%{NOTSPACE:domain}\\s%{IP:remote_addr}\\s%{NUMBER:request_time}s\\s\"%{DATA:upstream_ip}\"\\s\\[%{HTTPDATE:timestamp}\\]\\s\"%{NOTSPACE:method}\\s%{DATA:url}\\s%{NOTSPACE:http_ver}\"\\s%{NUMBER:status}\\s%{NUMBER:body_bytes_send}\\s%{DATA:referer}\\s%{NOTSPACE:cookie_info}\\s\"%{DATA:user_agent}'</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Elasticsearch中支持的格式</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "timestamp"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field = "datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format = "dd/MMM/yyyy:HH:mm:ss Z"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format = "yyyy-MM-dd'T'HH:mm:00.SSS+08:00"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ## 利用SQL对数据进行聚合</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select domain, hostname, status, datetime, count(*) from access_log group by domain, hostname, status, datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elasticsearch {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        hosts = ["localhost:9200"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index = "seatunnel-${now}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        es.batch.size.entries = 100000</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index_time_format = "yyyy.MM.dd"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel，即可将数据写入Elasticsearch。这里我们以本地模式为例。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/start-seatunnel.sh --config config/batch.conf -e client -m 'local[2]'</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>最后，写入Elasticsearch中的数据如下，再配上Kibana就可以实现Web服务的实时监控了^_^.</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">"_source": {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "domain": "elasticsearch.cn",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "hostname": "localhost",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "status": "200",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "datetime": "2018-11-26T21:54:00.000+08:00",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "count": 26</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  }</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何通过 Seatunnel 将Kafka中的数据写入Elasticsearch中。仅仅通过一个配置文件便可快速运行一个Spark Application，完成数据的处理、写入，无需编写任何代码，十分简单。</p><p>当数据处理过程中有遇到Logstash无法支持的场景或者Logstah性能无法达到预期的情况下，都可以尝试使用 Seatunnel 解决问题。</p><p>希望了解 Seatunnel 与Elasticsearch、Kafka、Hadoop结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><p><strong>我们近期会再发布一篇《如何用Spark和Elasticsearch做交互式数据分析》，敬请期待.</strong></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="contract-us">Contract us<a class="hash-link" href="#contract-us" title="Direct link to heading">​</a></h2><ul><li>邮件列表 : <strong><a href="mailto:dev@seatunnel.apache.org" target="_blank" rel="noopener noreferrer">dev@seatunnel.apache.org</a></strong>. 发送任意内容至 <code>dev-subscribe@seatunnel.apache.org</code>， 按照回复订阅邮件列表。</li><li>Slack: 发送 <code>Request to join SeaTunnel slack</code> 邮件到邮件列表 (<code>dev@seatunnel.apache.org</code>), 我们会邀请你加入（在此之前请确认已经注册Slack）.</li><li><a href="https://space.bilibili.com/1542095008" target="_blank" rel="noopener noreferrer">bilibili B站 视频</a></li></ul>]]></content>
        <category label="Spark" term="Spark"/>
        <category label="Kafka" term="Kafka"/>
        <category label="Elasticsearch" term="Elasticsearch"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[怎么用 Spark 在 TiDB 上做 OLAP 分析]]></title>
        <id>spark-execute-tidb</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/spark-execute-tidb"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[TiDB 是一款定位于在线事务处理/在线分析处理的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。]]></summary>
        <content type="html"><![CDATA[<p><img src="https://download.pingcap.com/images/tidb-planet.jpg"></p><p><a href="https://github.com/pingcap/tidb" target="_blank" rel="noopener noreferrer">TiDB</a> 是一款定位于在线事务处理/在线分析处理的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。</p><p>TiSpark 是 PingCAP 为解决用户复杂 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势。</p><p>直接使用 TiSpark 完成 OLAP 操作需要了解 Spark，还需要一些开发工作。那么，有没有一些开箱即用的工具能帮我们更快速地使用 TiSpark 在 TiDB 上完成 OLAP 分析呢？</p><p>目前开源社区上有一款工具 <strong>Seatunnel</strong>，项目地址 <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> ，可以基于Spark，在 TiSpark 的基础上快速实现 TiDB 数据读取和 OLAP 分析。</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="使用-seatunnel-操作tidb">使用 Seatunnel 操作TiDB<a class="hash-link" href="#使用-seatunnel-操作tidb" title="Direct link to heading">​</a></h2><p>在我们线上有这么一个需求，从 TiDB 中读取某一天的网站访问数据，统计每个域名以及服务返回状态码的访问次数，最后将统计结果写入 TiDB 另外一个表中。 我们来看看 Seatunnel 是如何实现这么一个功能的。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在 Spark 之上。Seatunnel 拥有着非常丰富的插件，支持从 TiDB、Kafka、HDFS、Kudu 中读取数据，进行各种各样的数据处理，然后将结果写入 TiDB、ClickHouse、Elasticsearch 或者 Kafka 中。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="准备工作">准备工作<a class="hash-link" href="#准备工作" title="Direct link to heading">​</a></h4><h5 class="anchor anchorWithStickyNavbar_mojV" id="1-tidb-表结构介绍">1. TiDB 表结构介绍<a class="hash-link" href="#1-tidb-表结构介绍" title="Direct link to heading">​</a></h5><p><strong>Input</strong>（存储访问日志的表）</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE access_log (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain VARCHAR(255),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    datetime VARCHAR(63),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remote_addr VARCHAR(63),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    http_ver VARCHAR(15),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    body_bytes_send INT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status INT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    request_time FLOAT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url TEXT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-----------------+--------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| Field           | Type         | Null | Key  | Default | Extra |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-----------------+--------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| domain          | varchar(255) | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| datetime        | varchar(63)  | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| remote_addr     | varchar(63)  | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| http_ver        | varchar(15)  | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| body_bytes_send | int(11)      | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| status          | int(11)      | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| request_time    | float        | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| url             | text         | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-----------------+--------------+------+------+---------+-------+</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><strong>Output</strong>（存储结果数据的表）</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE access_collect (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date VARCHAR(23),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain VARCHAR(63),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status INT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hit INT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+-------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| Field  | Type        | Null | Key  | Default | Extra |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+-------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| date   | varchar(23) | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| domain | varchar(63) | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| status | int(11)     | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| hit    | int(11)     | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+-------------+------+------+---------+-------+</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="2-安装-seatunnel">2. 安装 Seatunnel<a class="hash-link" href="#2-安装-seatunnel" title="Direct link to heading">​</a></h5><p>有了 TiDB 输入和输出表之后， 我们需要安装 Seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备 Spark环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 下载安装Spark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tar -xvf https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 下载安装seatunnel</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">https://github.com/InterestingLab/seatunnel/releases/download/v1.2.0/seatunnel-1.2.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip seatunnel-1.2.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd seatunnel-1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/seatunnel-env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 指定Spark安装路径</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SPARK_HOME=${SPARK_HOME:-/usr/local/spark-2.1.0-bin-hadoop2.7}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="实现-seatunnel-处理流程">实现 Seatunnel 处理流程<a class="hash-link" href="#实现-seatunnel-处理流程" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个 Seatunnel 配置文件即可完成数据的读取、处理、写入。</p><p>Seatunnel 配置文件由四个部分组成，分别是 <code>Spark</code>、<code>Input</code>、<code>Filter</code> 和 <code>Output</code>。<code>Input</code> 部分用于指定数据的输入源，<code>Filter</code> 部分用于定义各种各样的数据处理、聚合，<code>Output</code> 部分负责将处理之后的数据写入指定的数据库或者消息队列。</p><p>整个处理流程为 <code>Input</code> -&gt; <code>Filter</code> -&gt; <code>Output</code>，整个流程组成了 Seatunnel 的 处理流程（Pipeline）。</p><blockquote><p>以下是一个具体配置，此配置来源于线上实际应用，但是为了演示有所简化。</p></blockquote><h5 class="anchor anchorWithStickyNavbar_mojV" id="input-tidb">Input (TiDB)<a class="hash-link" href="#input-tidb" title="Direct link to heading">​</a></h5><p>这里部分配置定义输入源，如下是从 TiDB 一张表中读取数据。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "nginx"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from nginx.access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_nginx_input"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h5><p>在Filter部分，这里我们配置一系列的转化, 大部分数据分析的需求，都是在Filter完成的。Seatunnel 提供了丰富的插件，足以满足各种数据分析需求。这里我们通过 SQL 插件完成数据的聚合操作。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_nginx_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)='2019-01-20' group by domain, status, substring(datetime, 1, 10)"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="output-tidb">Output (TiDB)<a class="hash-link" href="#output-tidb" title="Direct link to heading">​</a></h5><p>最后， 我们将处理后的结果写入TiDB另外一张表中。TiDB Output是通过JDBC实现的</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        url = "jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;characterEncoding=utf8"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "access_collect"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        user = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        save_mode = "append"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h5><p>这一部分是 Spark 的相关配置，主要配置 Spark 执行时所需的资源大小以及其他 Spark 配置。</p><p>我们的 TiDB Input 插件是基于 TiSpark 实现的，而 TiSpark 依赖于 TiKV 集群和 Placement Driver (PD)。因此我们需要指定 PD 节点信息以及 TiSpark 相关配置<code>spark.tispark.pd.addresses</code>和<code>spark.sql.extensions</code>。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel-tidb"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  # Set for TiSpark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.tispark.pd.addresses = "localhost:2379"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.sql.extensions = "org.apache.spark.sql.TiExtensions"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="运行-seatunnel">运行 Seatunnel<a class="hash-link" href="#运行-seatunnel" title="Direct link to heading">​</a></h4><p>我们将上述四部分配置组合成我们最终的配置文件 <code>conf/tidb.conf</code></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.app.name = "seatunnel-tidb"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Set for TiSpark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.tispark.pd.addresses = "localhost:2379"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.sql.extensions = "org.apache.spark.sql.TiExtensions"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "nginx"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from nginx.access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_table"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_nginx_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)='2019-01-20' group by domain, status, substring(datetime, 1, 10)"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        url = "jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;characterEncoding=utf8"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "access_collect"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        user = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        save_mode = "append"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel ，即可实现我们的数据处理逻辑。</p><ul><li>Local</li></ul><blockquote><p>./bin/start-seatunnel.sh --config config/tidb.conf --deploy-mode client --master 'local<!-- -->[2]<!-- -->'</p></blockquote><ul><li>yarn-client</li></ul><blockquote><p>./bin/start-seatunnel.sh --config config/tidb.conf --deploy-mode client --master yarn</p></blockquote><ul><li>yarn-cluster</li></ul><blockquote><p>./bin/start-seatunnel.sh --config config/tidb.conf --deploy-mode cluster -master yarn</p></blockquote><p>如果是本机测试验证逻辑，用本地模式（Local）就可以了，一般生产环境下，都是使用<code>yarn-client</code>或者<code>yarn-cluster</code>模式。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="检查结果">检查结果<a class="hash-link" href="#检查结果" title="Direct link to heading">​</a></h4><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">mysql&gt; select * from access_collect;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------------+--------+--------+------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| date       | domain | status | hit  |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------------+--------+--------+------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 2019-01-20 | b.com  |    200 |   63 |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 2019-01-20 | a.com  |    200 |   85 |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------------+--------+--------+------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2 rows in set (0.21 sec)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="总结">总结<a class="hash-link" href="#总结" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何使用 Seatunnel 从 TiDB 中读取数据，做简单的数据处理之后写入 TiDB 另外一个表中。仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码。</p><p>除了支持 TiDB 数据源之外，Seatunnel 同样支持Elasticsearch, Kafka, Kudu, ClickHouse等数据源。</p><p><strong>于此同时，我们正在研发一个重要功能，就是在 Seatunnel 中，利用 TiDB 的事务特性，实现从 Kafka 到 TiDB 流式数据处理，并且支持端（Kafka）到端（TiDB）的 Exactly-Once 数据一致性。</strong></p><p>希望了解 Seatunnel 和 TiDB，ClickHouse、Elasticsearch、Kafka结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="联系我们">联系我们<a class="hash-link" href="#联系我们" title="Direct link to heading">​</a></h2><ul><li>邮件列表 : <strong><a href="mailto:dev@seatunnel.apache.org" target="_blank" rel="noopener noreferrer">dev@seatunnel.apache.org</a></strong>. 发送任意内容至 <code>dev-subscribe@seatunnel.apache.org</code>， 按照回复订阅邮件列表。</li><li>Slack: 发送 <code>Request to join SeaTunnel slack</code> 邮件到邮件列表 (<code>dev@seatunnel.apache.org</code>), 我们会邀请你加入（在此之前请确认已经注册Slack）.</li><li><a href="https://space.bilibili.com/1542095008" target="_blank" rel="noopener noreferrer">bilibili B站 视频</a></li></ul><p>-- Power by <a href="https://github.com/InterestingLab" target="_blank" rel="noopener noreferrer">InterestingLab</a></p>]]></content>
        <category label="Spark" term="Spark"/>
        <category label="TiDB" term="TiDB"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何支持的 Spark StructuredStreaming]]></title>
        <id>spark-structured-streaming</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/spark-structured-streaming"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[前言]]></summary>
        <content type="html"><![CDATA[<h3 class="anchor anchorWithStickyNavbar_mojV" id="前言">前言<a class="hash-link" href="#前言" title="Direct link to heading">​</a></h3><p>StructuredStreaming是Spark 2.0以后新开放的一个模块，相比SparkStreaming，它有一些比较突出的优点：<br> <!-- --> <!-- --> <!-- -->一、它能做到更低的延迟;<br>
<!-- --> <!-- --> <!-- -->二、可以做实时的聚合，例如实时计算每天每个商品的销售总额；<br>
<!-- --> <!-- --> <!-- -->三、可以做流与流之间的关联，例如计算广告的点击率，需要将广告的曝光记录和点击记录关联。<br>
以上几点如果使用SparkStreaming来实现可能会比较麻烦或者说是很难实现，但是使用StructuredStreaming实现起来会比较轻松。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="如何使用structuredstreaming">如何使用StructuredStreaming<a class="hash-link" href="#如何使用structuredstreaming" title="Direct link to heading">​</a></h3><p>可能你没有详细研究过StructuredStreaming，但是发现StructuredStreaming能很好的解决你的需求，如何快速利用StructuredStreaming来解决你的需求？目前社区有一款工具 <strong>Seatunnel</strong>，项目地址：<a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> ,
可以高效低成本的帮助你利用StructuredStreaming来完成你的需求。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p>Seatunnel 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上。Seatunnel 拥有着非常丰富的插件，支持从Kafka、HDFS、Kudu中读取数据，进行各种各样的数据处理，并将结果写入ClickHouse、Elasticsearch或者Kafka中</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="准备工作">准备工作<a class="hash-link" href="#准备工作" title="Direct link to heading">​</a></h3><p>首先我们需要安装 Seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备Spark环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tar -xvf https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://github.com/InterestingLab/seatunnel/releases/download/v1.3.0/seatunnel-1.3.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip seatunnel-1.3.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd seatunnel-1.3.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/seatunnel-env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 指定Spark安装路径</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SPARK_HOME=${SPARK_HOME:-/usr/local/spark-2.2.0-bin-hadoop2.7}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">Seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个 Seatunnel Pipeline的配置文件即可完成数据的导入。</p><p>配置文件包括四个部分，分别是Spark、Input、filter和Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是Spark的相关配置，主要配置Spark执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>下面是一个从kafka读取数据的例子</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    topics = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    schema = "{\"name\":\"string\",\"age\":\"integer\",\"addrs\":{\"country\":\"string\",\"city\":\"string\"}}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>通过上面的配置就可以读取kafka里的数据了 ，topics是要订阅的kafka的topic，同时订阅多个topic可以以逗号隔开，consumer.bootstrap.servers就是Kafka的服务器列表，schema是可选项，因为StructuredStreaming从kafka读取到的值(官方固定字段value)是binary类型的，详见<a href="http://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html" target="_blank" rel="noopener noreferrer">http://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html</a>
但是如果你确定你kafka里的数据是json字符串的话，你可以指定schema，input插件将按照你指定的schema解析</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>下面是一个简单的filter例子</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "student"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select name,age from student"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><code>table_name</code>是注册成的临时表名，以便于在下面的sql使用</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>处理好的数据往外输出，假设我们的输出也是kafka</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafka {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topic = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        producer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        streaming_output_mode = "update"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpointLocation = "/your/path"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><code>topic</code> 是你要输出的topic，<code> producer.bootstrap.servers</code>是kafka集群列表，<code>streaming_output_mode</code>是StructuredStreaming的一个输出模式参数，有三种类型<code>append|update|complete</code>，具体使用参见文档<a href="http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-modes" target="_blank" rel="noopener noreferrer">http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-modes</a></p><p><code>checkpointLocation</code>是StructuredStreaming的checkpoint路径，如果配置了的话，这个目录会存储程序的运行信息，比如程序退出再启动的话会接着上次的offset进行消费。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="场景分析">场景分析<a class="hash-link" href="#场景分析" title="Direct link to heading">​</a></h3><p>以上就是一个简单的例子，接下来我们就来介绍的稍微复杂一些的业务场景</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="场景一实时聚合场景">场景一：实时聚合场景<a class="hash-link" href="#场景一实时聚合场景" title="Direct link to heading">​</a></h4><p>假设现在有一个商城，上面有10种商品，现在需要实时求每天每种商品的销售额，甚至是求每种商品的购买人数（不要求十分精确）。
这么做的巨大的优势就是海量数据可以在实时处理的时候，完成聚合，再也不需要先将数据写入数据仓库，再跑离线的定时任务进行聚合，
操作起来还是很方便的。</p><p>kafka的数据如下</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{"good_id":"abc","price":300,"user_id":123456,"time":1553216320}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>那我们该怎么利用 Seatunnel 来完成这个需求呢，当然还是只需要配置就好了。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">#spark里的配置根据业务需求配置</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#配置input</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "good_topic"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schema = "{\"good_id\":\"string\",\"price\":\"integer\",\"user_id\":\"Long\",\"time\":\"Long\"}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#配置filter    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #在程序做聚合的时候，内部会去存储程序从启动开始的聚合状态，久而久之会导致OOM,如果设置了watermark，程序自动的会去清理watermark之外的状态</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #这里表示使用ts字段设置watermark，界限为1天</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Watermark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        time_field = "time"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        time_type = "UNIX"              #UNIX表示时间字段为10为的时间戳，还有其他的类型详细可以查看插件文档</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        time_pattern = "yyyy-MM-dd"     #这里之所以要把ts对其到天是因为求每天的销售额，如果是求每小时的销售额可以对其到小时`yyyy-MM-dd HH`</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        delay_threshold = "1 day"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        watermark_field = "ts"          #设置watermark之后会新增一个字段，`ts`就是这个字段的名字</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #之所以要group by ts是要让watermark生效，approx_count_distinct是一个估值，并不是精确的count_distinct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "good_table_2"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select good_id,sum(price) total, approx_count_distinct(user_id) person from good_table_2 group by ts,good_id"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#接下来我们选择将结果实时输出到Kafka</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafka {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topic = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        producer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        streaming_output_mode = "update"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpointLocation = "/your/path"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>如上配置完成，启动 Seatunnel，就可以获取你想要的结果了。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="场景二多个流关联场景">场景二：多个流关联场景<a class="hash-link" href="#场景二多个流关联场景" title="Direct link to heading">​</a></h4><p>假设你在某个平台投放了广告，现在要实时计算出每个广告的CTR(点击率)，数据分别来自两个topic，一个是广告曝光日志，一个是广告点击日志,
此时我们就需要把两个流数据关联到一起做计算，而 Seatunnel 最近也支持了此功能，让我们一起看一下该怎么做：</p><p>点击topic数据格式</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{"ad_id":"abc","click_time":1553216320,"user_id":12345}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>曝光topic数据格式</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{"ad_id":"abc","show_time":1553216220,"user_id":12345}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">#spark里的配置根据业务需求配置</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#配置input</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "click_topic"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schema = "{\"ad_id\":\"string\",\"user_id\":\"Long\",\"click_time\":\"Long\"}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "click_table"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "show_topic"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schema = "{\"ad_id\":\"string\",\"user_id\":\"Long\",\"show_time\":\"Long\"}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "show_table"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #左关联右表必须设置watermark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #右关左右表必须设置watermark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#inner-joins-with-optional-watermarking</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Watermark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              source_table_name = "click_table" #这里可以指定为某个临时表添加watermark，不指定的话就是为input中的第一个</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              time_field = "time"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              time_type = "UNIX"               </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              delay_threshold = "3 hours"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              watermark_field = "ts" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              result_table_name = "click_table_watermark" #添加完watermark之后可以注册成临时表，方便后续在sql中使用</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Watermark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                source_table_name = "show_table" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                time_field = "time"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                time_type = "UNIX"               </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                delay_threshold = "2 hours"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                watermark_field = "ts" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                result_table_name = "show_table_watermark" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "show_table_watermark"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select a.ad_id,count(b.user_id)/count(a.user_id) ctr from show_table_watermark as a left join click_table_watermark as b on a.ad_id = b.ad_id and a.user_id = b.user_id "</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#接下来我们选择将结果实时输出到Kafka</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafka {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topic = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        producer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        streaming_output_mode = "append" #流关联只支持append模式</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpointLocation = "/your/path"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>通过配置，到这里流关联的案例也完成了。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="结语">结语<a class="hash-link" href="#结语" title="Direct link to heading">​</a></h3><p>通过配置能很快的利用StructuredStreaming做实时数据处理，但是还是需要对StructuredStreaming的一些概念了解，比如其中的watermark机制，还有程序的输出模式。</p><p>最后，Seatunnel 当然还支持spark streaming和spark 批处理。
如果你对这两个也感兴趣的话，可以阅读我们以前发布的文章《<a href="/zh-CN/blog/hive-to-clickhouse">如何快速地将Hive中的数据导入ClickHouse</a>》、
《<a href="/zh-CN/blog/spark-execute-tidb">优秀的数据工程师，怎么用Spark在TiDB上做OLAP分析</a>》、
《<a href="/zh-CN/blog/spark-execute-elasticsearch">如何使用Spark快速将数据写入Elasticsearch</a>》</p><p>希望了解 Seatunnel 和 HBase, ClickHouse、Elasticsearch、Kafka、MySQL 等数据源结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="联系我们">联系我们<a class="hash-link" href="#联系我们" title="Direct link to heading">​</a></h2><ul><li>邮件列表 : <strong><a href="mailto:dev@seatunnel.apache.org" target="_blank" rel="noopener noreferrer">dev@seatunnel.apache.org</a></strong>. 发送任意内容至 <code>dev-subscribe@seatunnel.apache.org</code>， 按照回复订阅邮件列表。</li><li>Slack: 发送 <code>Request to join SeaTunnel slack</code> 邮件到邮件列表 (<code>dev@seatunnel.apache.org</code>), 我们会邀请你加入（在此之前请确认已经注册Slack）.</li><li><a href="https://space.bilibili.com/1542095008" target="_blank" rel="noopener noreferrer">bilibili B站 视频</a></li></ul>]]></content>
        <category label="Spark" term="Spark"/>
        <category label="StructuredStreaming" term="StructuredStreaming"/>
    </entry>
</feed>