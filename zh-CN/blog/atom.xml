<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://seatunnel.apache.org/zh-CN/blog</id>
    <title>Apache SeaTunnel Blog</title>
    <updated>2022-03-18T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://seatunnel.apache.org/zh-CN/blog"/>
    <subtitle>Apache SeaTunnel Blog</subtitle>
    <icon>https://seatunnel.apache.org/zh-CN/image/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Apache SeaTunnel(Incubating) 首个Apache 版本 2.1.0 发布，内核重构，全面支持Flink]]></title>
        <id>Apache SeaTunnel(Incubating) 首个Apache 版本 2.1.0 发布，内核重构，全面支持Flink</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/Apache SeaTunnel(Incubating) 首个Apache 版本 2.1.0 发布，内核重构，全面支持Flink"/>
        <updated>2022-03-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[2021 年 12 月 9 日，Apache SeaTunnel(Incubating) 进入 Apache 孵化器，在经过社区各位贡献者近四个月的努力下，我们于2022年3月18日发布了首个Apache版本，并且保证了首个版本一次性通过检查。这意味着 2.1.0 版本，是经过 Apache SeaTunnel(Incubating) 社区和 Apache 孵化器投票检查发布的官方版本，企业和个人用户可以放心安全使用。]]></summary>
        <category label="2.1.0" term="2.1.0"/>
        <category label="Release" term="Release"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[SeaTunnel 在唯品会的实践]]></title>
        <id>SeaTunnel 在唯品会的实践</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/SeaTunnel 在唯品会的实践"/>
        <updated>2022-02-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[分享嘉宾：唯品会 资深大数据工程师 王玉]]></summary>
        <content type="html"><![CDATA[<p>分享嘉宾：唯品会 资深大数据工程师 王玉
讲稿整理：张德通</p><p>导读: 唯品会早在1.0版本时就引用了SeaTunnel，我们使用SeaTunnel进行一些Hive到ClickHouse之间数据交互的工作。
今天的介绍会围绕下面几点展开：</p><ul><li>ClickHouse数据导入的需求和痛点；</li><li>ClickHouse出仓入仓工具选型；</li><li>Hive to ClickHouse；</li><li>ClickHouse to Hive；</li><li>SeaTunnel与唯品会数据平台的集成；</li><li>未来展望；</li></ul><h1>ClickHouse数据导入的需求和痛点</h1><h2 class="anchor anchorWithStickyNavbar_mojV" id="1唯品会数据olap架构">1.唯品会数据OLAP架构<a class="hash-link" href="#1唯品会数据olap架构" title="Direct link to heading">​</a></h2><p>图中是唯品会OLAP架构，我们负责的模块是图中的数据服务和计算引擎两大部分。底层依赖的数据仓库分为离线数仓、实时数仓和湖仓。计算引擎方面，我们使用Presto、Kylin和Clickhouse。虽然Clickhouse是一个存储一体的OLAP数据库，我们为了利用Clickhouse的优秀计算性能而将它归入了计算引擎部分。基于OLAP组件之上，我们提供了SQL类数据服务和非SQL的唯品会自主分析，为不同智能服务。例如非SQL服务是为BI和商务提供更贴近业务的数据分析的服务。在数据服务至上抽象了多个数据应用。
<img loading="lazy" alt="1" src="/zh-CN/assets/images/1-1-f0cdf48f8c90391d9e8cfe410fc32bb1.png" width="2038" height="1440"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="2需求">2.需求<a class="hash-link" href="#2需求" title="Direct link to heading">​</a></h2><p>我们通过Presto Connector和Spark组件，把底层的Hive、Kudu、Alluxio组件打通。大数据组件之间可以互相导入导出数据，可以根据数据分析的需求和场景任意利用合适的组件分析数据。但我们引入Clickhouse时，它是一个数据孤岛，数据的导入和导出比较困难。Hive和Clickhouse之间需要做很多工作才能实现导入导出。我们的第一个数据导入导出需求就是提升导入导出效率，把Clickhouse纳入大数据体系中。
<img loading="lazy" alt="2" src="/zh-CN/assets/images/2-0b1a1413f99ac6195aefc2146ba07c4b.png" width="2037" height="1440"></p><p>第二个需求是Presto跑SQL比较慢，图中是一个慢SQL的例子。图中的SQL where条件设置了日期、时间范围和具体过滤条件，这类SQL使用由于Presto使用分区粒度下推，运行比较慢。即使用Hive的Bucket表和分桶等其他方式优化后也是几秒的返回时间、不能满足业务要求。这种情况下，我们需要利用Clickhouse做离线的OLAP计算加速。
<img loading="lazy" alt="3" src="/zh-CN/assets/images/3-a762d5f3914268cbc2b478215d8da72d.png" width="2035" height="1440"></p><p>我们的实时数据是通过Kafka、Flink SQL方式写入到Clickhouse中。但分析时只用实时数据是不够的，需要用Hive维度表和已经ETL计算号的T+1实时表一起在Clickhouse中做加速运输。这需要把Hive的数据导入到Clickhouse中，这就是我们的第三个需求。
<img loading="lazy" alt="4" src="/zh-CN/assets/images/4-03112bb3e1bca7cc97ab7868fbdf6d78.png" width="2035" height="1440"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="3痛点">3.痛点<a class="hash-link" href="#3痛点" title="Direct link to heading">​</a></h2><p>首先，我们引入一项数据组件时要考虑其性能。Hive表粒度是五分钟，是否有组件可以支撑五分钟内完成一个短小ETL流程并把ETL结果导入到Clickhouse中？第二，我们需要保证数据质量，数据的准确性需要有保障。Hive和Clickhouse的数据条数需要保障一致性，如果数据质量出问题能否通过重跑等机制修复数据？第三，数据导入需要支持的数据类型是否完备？不同数据库之间的数据类型和一些机制不同，我们有HiperLogLog和BitMap这类在某一存储引擎中利用得比较多得数据类型，是否可以正确传输和识别，且可以较好地使用。</p><h1>ClickHouse和Hive出仓入仓工具的选型</h1><p>基于数据业务上的痛点，我们对数据出仓入仓工具进行了对比和选择。我们主要在开源工具中进行选择，没有考虑商业出入仓工具，主要对比DataX、SeaTunnel和编写Spark程序并用jdbc插入ClickHouse这三个方案中取舍。
SeaTunnel和Spark依赖唯品会自己的Yarn集群，可以直接实现分布式读取和写入。DataX是非分布式的，且Reader、Writer之间的启动过程耗时时间长，性能普通，SeaTunnel和Spark处理数据的性能可以达到DataX的数倍。
十亿以上的数据可以平稳地在SeaTunnel和Spark中运行，DataX在数据量大以后性能压力大，处理十亿以上数据吃力。
在读写插件扩展性方面，SeaTunnel支持了多种数据源，支持用户开发插件。SeaTunnel支持了数据导入Redis。
稳定性上，SeaTunnel和DataX由于是自成体系的工具，稳定性会更好。Spark的稳定性方面需要关注代码质量。
<img loading="lazy" alt="5" src="/zh-CN/assets/images/5-e5c4ff850add4f0334c2f9a0de839c53.png" width="2035" height="1440"></p><p>我们的曝光表数据量每天在几十亿级，我们有5min内完成数据处理的性能要求，我们我们存在数据导入导出到Redis的需求，我们需要导入导出工具可以接入到数据平台上进行任务调度。 出于数据量级、性能、可扩展性、平台兼容性几方面的考虑，我们选择了SeaTunnel作为我们的数仓导入导出工具。</p><h1>Hive数据导入到ClickHouse</h1><p>下面将介绍我们对SeaTunnel的使用。
图中是一张Hive表，它是我们三级的商品维度表，包含品类商品、维度品类和用户人群信息。表的主键是一个三级品类ct_third_id，下面的value是两个uid的位图，是用户id的bitmap类型，我们要把这个Hive表导入到Clickhouse。
<img loading="lazy" alt="6" src="/zh-CN/assets/images/6-e37187a14e8316f82074f78b8a250a58.png" width="2036" height="1440"></p><p>SeaTunnel安装简单，官网文档有介绍如何安装。下图中是SeaTunnel的配置，配置中env、source和sink是必不可少的。env部分，图中的例子是Spark配置，配置了包括并发度等，可以调整这些参数。source部分是数据来源，这里配置了Hive数据源，包括一条Hive Select语句，Spark运行source配置中的SQL把数据读出，此处支持UDF进行简单ETL；sink部分配置了Clickhouse，可以看到output_type=rowbinary，rowbinary是唯品会自研加速方案；pre_sql和check_sql是自研的用于数据校验的功能，后面也会详细介绍；clickhouse.socket_timeout和bulk_size都是可以根据实际情况进行调整的。
<img loading="lazy" alt="7" src="/zh-CN/assets/images/7-70fd49824f2fe94faa0ed91b9e31fdf6.png" width="2037" height="1440"></p><p>运行SeaTunnel，执行sh脚本文件、配置conf文件地址和yarn信息，后即可。
<img loading="lazy" alt="8" src="/zh-CN/assets/images/8-fa6d66bcb7d1a37038666d5d63c64d3d.png" width="2038" height="1440">
运行过程中会产生Spark日志，运行成功和运行中错误都可以在日志中查看。
<img loading="lazy" alt="9" src="/zh-CN/assets/images/9-f08855ea40230b4f16d6c04408063346.png" width="2038" height="1440"></p><p>为了更贴合业务，唯品会对SeaTunnel做了一些改进。我们的ETL任务都是需要重跑的，我们支持了pre_sql和check_sql实现数据的重跑和对数。主要流程是在数据准备好后，执行pre_sql进行预处理，在Clickhouse中执行删除旧分区数据、存放到某一目录下在失败时恢复该分区、rename这类操作。check_sql会检验，校验通过后整个流程结束；如果检验不通过，根据配置进行重跑，重跑不通过则报警到对应负责人。
<img loading="lazy" alt="10" src="/zh-CN/assets/images/10-15459320d13177fafe0fd49a06f92e03.png" width="2037" height="1440"></p><p>唯品会基于1.0版本SeaTunnel增加了RowBinary做加速，也让HuperLogLog和BinaryBitmap的二进制文件能更容易地从Hive导入到Clickhouse。我们在ClickHouse-jdbc、bulk_size、Hive-source几处进行了修改。使用CK-jdbc的extended api，以rowbinary方式将数据写入CK，bulk_size引入了以rowbinary方式写入CK的控制逻辑，Hive-source
RDD以HashPartitioner进行分区将数据打散，防止数据倾斜。</p><p>我们还让SeaTunnel支持了多类型，为了圈人群的功能，需要在Clickhouse、Preso、Spark中实现对应的方法。我们在Clickhouse-jdbc中增加支持Batch特性的Callback、HttpEntity、RowBinaryStream，在Clickhouse-jdbc和Clickhouse-sink代码中增加了bitmap类型映射，在Presto和Spark中实现了Clickhouse的Hyperloglog和Bitmap的function的UDF。
前面的配置中，Clickhouse-sink部分可以指定表名，这里有写入本地表和分布式表的差异。写入分布式表的性能比写入本地表差对Clickhouse集群的压力会更大，但在计算曝光表、流量表，ABTest等场景中需要两表Join，两张表量级均在几十亿。这时我们希望Join key落在本机，Join成本更小。我们建表时在Clickhouse的分布式表分布规则中配置murmurHash64规则，然后在Seatunnel的sink里直接配置分布式表，把写入规则交给Clickhouse，利用了分布式表的特性进行写入。写入本地表对Clickhouse的压力会更小，写入的性能也会更好。我们在Seatunnel里，根据sink的本地表，去Clickhouse的System.cluster表里获取表的分布信息和机器分布host。然后根据均分规则写入这些host。把数据分布式写入的事情放到Seatunnel里来做。
针对本地表和分布式表的写入，我们未来的改造方向是在Seatunnel实现一致性哈希，直接按照一定规则写如Clickhouse、不依赖Clickhouse自身做数据分发，改善Clickhouse高CPU负载问题。</p><h1>ClickHouse数据导入到Hive</h1><p>我们有圈人群的需求，每天唯品会为供应商圈20万个人群，比如80后、高富帅、白富美的人群集合。这些在Clickhouse中的Bitmap人群信息需要导出到Hive表，在Hive中与其他ETL任务进行配合，最后推到PIKA交给外部媒体使用。我们使SeaTunnel将Clickhouse Bitmap人群数据反推到Hive。
<img loading="lazy" alt="11" src="/zh-CN/assets/images/11-8f601d01cedafe8901b091b5ddcefd59.png" width="2035" height="1440"></p><p>图中是SeaTunnel配置，我们把source配置为Clickhouse、sink配置为Hive，数据校验也配置在Hive内。
<img loading="lazy" alt="12" src="/zh-CN/assets/images/12-9a03852b4e4065b3f9f909da1bb4b672.png" width="2035" height="1440"></p><p>由于我们接入SeaTunnel较早，我们对一些模块间进行了加工，包括新增plugin-spark-sink-hive模块、plugin-spark-source-ClickHouse模块，重写Spark Row相关方法，使其能封装经过Schem映射后的Clickhouse数据，重新构造StructField并生成最终需要落地Hive的DataFrame。最新版本已经有了很多source和sink组件，在SeaTunnel使用上更方便。现在也可以在SeaTunnel中直接集成Flink connector。</p><h1>SeaTunnel与唯品会数据平台的集成</h1><p>各个公司都有自己的调度系统，例如白鲸、宙斯。唯品会的调度工具是数坊，调度工具中集成了数据传输工具。下面是调度系统架构图，其中包含各类数据的出入仓。
<img loading="lazy" alt="13" src="/zh-CN/assets/images/13-c93b070b1abe679688f557f3b6bcfc52.png" width="2036" height="1440"></p><p>SeaTunnel任务类型集成到平台中，图中是数坊的定时任务截图，可以看到选中的部分，是一个配置好的SeaTunnel任务，负责人、最近一次耗时，前后依赖任务的血缘信息，消耗的资源信息。下面展示了历史运行实例信息。
<img loading="lazy" alt="14" src="/zh-CN/assets/images/14-654566bbfb5ed478b1a9dcd28f2dba72.png" width="2037" height="1440"></p><p>我们把SeaTunnel集成到了调度系统中，数坊调度Master会根据任务类型把任务分配到对应的Agent上，根据Agent负载情况分配到合适的机器上运行，管控器把前台的任务调度配置和信息拉取到后生成SeaTunnel cluster，在类似于k8s pod、cgroup隔离的虚拟环境内进行执行。运行结果会由调度平台的数据质量监控判断任务是否完成、是否运行成功，失败时进行重跑和告警。
<img loading="lazy" alt="15" src="/zh-CN/assets/images/15-798a1029db30ff228befcc333645c3e4.png" width="2038" height="1440"></p><p>SeaTunnel本身是一个工具化的组件，是为了进行数据血缘，数据质量，历史记录，高警监控，还包括资源分配这些信息的管控。我们把SeaTunnel集成到平台中，可以利用平台优势利用好SeaTunnel。
圈存人群中利用了SeaTunnel进行处理。我们通过打点数据，把圈存人群按照路径和使用情况分为不同的人，或称千人千面，把用户打上标签，圈出的某一类人群推送给用户、分析师和供应商。
<img loading="lazy" alt="16" src="/zh-CN/assets/images/16-8947f00847b3a55a537124964206e1b2.png" width="2036" height="1440"></p><p>流量进入Kafka，通过Flink入仓，再通过ETL形成用户标签表，用户标签表生成后，我们通过Presto实现了的BitMap方法，把数据打成Hive中的宽表。用户通过在人群系统页面中框选词条创建任务，提交腾群，生成SQL查询Clickhouse BitMap。Clickhouse的BitMap查询速度非常快，由天生优势，我们需要把Hive的BitMap表通过SeaTunnel导入到Clickhouse中。圈完人群后我们需要把表落地，形成Clickhouse的一个分区或一条记录，再把生成的结果BitMap表通过SeaTunnel存储到Hive中去。最后同步工具会将Hive的BitMap人群结果同步给外部媒体仓库Pika。每天圈20w个人群左右。
整个过程中SeaTunnel负责把数据从Hive导出到Clickhouse，Clickhouse的ETL流程完成后SeaTunnel把数据从Clickhouse导出到Hive。
为了完成这样的需求，我们在Presto和Spark端现ClickHouse的Hyperloglog和BitMap的function的UDF；我们还开发Seatunnel接口，使得用户在ClickHouse里使用Bitmap方法圈出来的人群，可以直接通过Seatunnel写入Hive表，无需中间落地步骤。用户也可以在Hive里通过spark圈人群或者反解人群bitmap，调用SeaTunnel接口，使数据直接传输到ClickHouse的结果表，而无需中间落地。</p><h1>后续工作</h1><p>后续我们会进一步改善Clickhouse写入数据时CPU负载高的问题，下一步会在SeaTunnel中实现Clickhouse数据源和读取端的CK-local模式，读写分离，减轻Clickhouse压力。未来我们也会增加更多sink支持，如数据推送到Pika和相应的数据检查。</p>]]></content>
        <category label="唯品会" term="唯品会"/>
        <category label="ClickHouse" term="ClickHouse"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何快速地把 HDFS 中的数据导入 ClickHouse]]></title>
        <id>hdfs-to-clickhouse</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/hdfs-to-clickhouse"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[ClickHouse 是面向 OLAP 的分布式列式 DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至 ClickHouse 这个优秀的数据仓库之中，当前日数据量达到了 300 亿。]]></summary>
        <content type="html"><![CDATA[<p>ClickHouse 是面向 OLAP 的分布式列式 DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至 ClickHouse 这个优秀的数据仓库之中，当前日数据量达到了 300 亿。</p><p>之前介绍的有关数据处理入库的经验都是基于实时数据流，数据存储在 Kafka 中，我们使用 Java 或者 Golang 将数据从 Kafka 中读取、解析、清洗之后写入 ClickHouse 中，这样可以实现数据的快速接入。然而在很多同学的使用场景中，数据都不是实时的，可能需要将 HDFS 或者是 Hive 中的数据导入 ClickHouse。有的同学通过编写 Spark 程序来实现数据的导入，那么是否有更简单、高效的方法呢。</p><p>目前开源社区上有一款工具 <strong>Seatunnel</strong>，项目地址 <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a>，可以快速地将 HDFS 中的数据导入 ClickHouse。</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="hdfs-to-clickhouse">HDFS To ClickHouse<a class="hash-link" href="#hdfs-to-clickhouse" title="Direct link to heading">​</a></h2><p>假设我们的日志存储在 HDFS 中，我们需要将日志进行解析并筛选出我们关心的字段，将对应的字段写入 ClickHouse 的表中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="log-sample">Log Sample<a class="hash-link" href="#log-sample" title="Direct link to heading">​</a></h3><p>我们在 HDFS 中存储的日志格式如下， 是很常见的 Nginx 日志</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token number">10.41</span><span class="token plain">.1.28 github.com </span><span class="token number">114.250</span><span class="token plain">.140.241 </span><span class="token number">0</span><span class="token plain">.001s </span><span class="token string" style="color:rgb(255, 121, 198)">"127.0.0.1:80"</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">26</span><span class="token plain">/Oct/2018:03:09:32 +0800</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"GET /Apache/Seatunnel HTTP/1.1"</span><span class="token plain"> </span><span class="token number">200</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"-"</span><span class="token plain"> - </span><span class="token string" style="color:rgb(255, 121, 198)">"Dalvik/2.1.0 (Linux; U; Android 7.1.1; OPPO R11 Build/NMF26X)"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"196"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"-"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"mainpage"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"443"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"-"</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"172.16.181.129"</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="clickhouse-schema">ClickHouse Schema<a class="hash-link" href="#clickhouse-schema" title="Direct link to heading">​</a></h3><p>我们的 ClickHouse 建表语句如下，我们的表按日进行分区</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE cms.cms_msg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> Date, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    datetime DateTime, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    request_time Float32, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">hostname</span><span class="token plain"> String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remote_addr String, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    data_size Int32, </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    pool String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> ENGINE </span><span class="token operator">=</span><span class="token plain"> MergeTree PARTITION BY </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> ORDER BY </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> SETTINGS index_granularity </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">16384</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-with-clickhouse">Seatunnel with ClickHouse<a class="hash-link" href="#seatunnel-with-clickhouse" title="Direct link to heading">​</a></h2><p>接下来会给大家详细介绍，我们如何通过 Seatunnel 满足上述需求，将 HDFS 中的数据写入 ClickHouse 中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上。Seatunnel 拥有着非常丰富的插件，支持从 Kafka、HDFS、Kudu 中读取数据，进行各种各样的数据处理，并将结果写入 ClickHouse、Elasticsearch 或者 Kafka 中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="prerequisites">Prerequisites<a class="hash-link" href="#prerequisites" title="Direct link to heading">​</a></h3><p>首先我们需要安装 Seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备 Spark 环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">wget</span><span class="token plain"> https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">tar</span><span class="token plain"> -xvf https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">wget</span><span class="token plain"> https://github.com/InterestingLab/seatunnel/releases/download/v1.1.1/seatunnel-1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">unzip</span><span class="token plain"> seatunnel-1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> seatunnel-1.1.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">vim</span><span class="token plain"> config/seatunnel-env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># 指定Spark安装路径</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">SPARK_HOME</span><span class="token operator">=</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">${SPARK_HOME</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">:-</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">/</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">usr</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">/</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">local</span><span class="token variable operator" style="color:rgb(189, 147, 249);font-style:italic">/</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">spark-2.2.0-bin-hadoop2.7}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个 seatunnel Pipeline 的配置文件即可完成数据的导入。</p><p>配置文件包括四个部分，分别是 Spark、Input、filter 和 Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是 Spark 的相关配置，主要配置 Spark 执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"1g"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>这一部分定义数据源，如下是从 HDFS 文件中读取 text 格式数据的配置案例。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">input </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hdfs </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        path </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"hdfs://nomanode:8020/rowlog/accesslog"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">format</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"text"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>在 Filter 部分，这里我们配置一系列的转化，包括正则解析将日志进行拆分、时间转换将 HTTPDATE 转化为 ClickHouse 支持的日期格式、对 Number 类型的字段进行类型转换以及通过 SQL 进行字段筛减等</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用正则解析原始日志</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"raw_message"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'%{IP:ha_ip}\\s%{NOTSPACE:domain}\\s%{IP:remote_addr}\\s%{NUMBER:request_time}s\\s\"%{DATA:upstream_ip}\"\\s\\[%{HTTPDATE:timestamp}\\]\\s\"%{NOTSPACE:method}\\s%{DATA:url}\\s%{NOTSPACE:http_ver}\"\\s%{NUMBER:status}\\s%{NUMBER:body_bytes_send}\\s%{DATA:referer}\\s%{NOTSPACE:cookie_info}\\s\"%{DATA:user_agent}\"\\s%{DATA:uid}\\s%{DATA:session_id}\\s\"%{DATA:pool}\"\\s\"%{DATA:tag2}\"\\s%{DATA:tag3}\\s%{DATA:tag4}'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># "yyyy/MM/dd HH:mm:ss"格式的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"timestamp"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"dd/MMM/yyyy:HH:mm:ss Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"yyyy/MM/dd HH:mm:ss"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用SQL筛选关注的字段，并对字段进行处理</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 甚至可以通过过滤条件过滤掉不关心的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"select substring(date, 1, 10) as date, datetime, hostname, url, http_code, float(request_time), int(data_size), domain from access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>最后我们将处理好的结构化数据写入 ClickHouse</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">host</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"your.clickhouse.host:8123"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"date"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"hostname"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"uri"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"http_code"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"request_time"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"data_size"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"domain"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"username"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"password"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="running-seatunnel">Running seatunnel<a class="hash-link" href="#running-seatunnel" title="Direct link to heading">​</a></h3><p>我们将上述四部分配置组合成为我们的配置文件 <code>config/batch.conf</code>。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">vim</span><span class="token plain"> config/batch.conf</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"1g"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hdfs </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        path </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"hdfs://nomanode:8020/rowlog/accesslog"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">format</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"text"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用正则解析原始日志</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"raw_message"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'%{IP:ha_ip}\\s%{NOTSPACE:domain}\\s%{IP:remote_addr}\\s%{NUMBER:request_time}s\\s\"%{DATA:upstream_ip}\"\\s\\[%{HTTPDATE:timestamp}\\]\\s\"%{NOTSPACE:method}\\s%{DATA:url}\\s%{NOTSPACE:http_ver}\"\\s%{NUMBER:status}\\s%{NUMBER:body_bytes_send}\\s%{DATA:referer}\\s%{NOTSPACE:cookie_info}\\s\"%{DATA:user_agent}\"\\s%{DATA:uid}\\s%{DATA:session_id}\\s\"%{DATA:pool}\"\\s\"%{DATA:tag2}\"\\s%{DATA:tag3}\\s%{DATA:tag4}'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># "yyyy/MM/dd HH:mm:ss"格式的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token function" style="color:rgb(80, 250, 123)">date</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"timestamp"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"dd/MMM/yyyy:HH:mm:ss Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"yyyy/MM/dd HH:mm:ss"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用SQL筛选关注的字段，并对字段进行处理</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 甚至可以通过过滤条件过滤掉不关心的数据</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"select substring(date, 1, 10) as date, datetime, hostname, url, http_code, float(request_time), int(data_size), domain from access"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token function" style="color:rgb(80, 250, 123)">host</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"your.clickhouse.host:8123"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"seatunnel"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"access_log"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"date"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"datetime"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"hostname"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"uri"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"http_code"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"request_time"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"data_size"</span><span class="token plain">, </span><span class="token string" style="color:rgb(255, 121, 198)">"domain"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"username"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"password"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel，即可将数据写入 ClickHouse。这里我们以本地模式为例。</p><div class="codeBlockContainer_I0IT language-shell theme-code-block"><div class="codeBlockContent_wNvx shell"><pre tabindex="0" class="prism-code language-shell codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/start-seatunnel.sh --config config/batch.conf -e client -m </span><span class="token string" style="color:rgb(255, 121, 198)">'local[2]'</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何使用 Seatunnel 将 HDFS 中的 Nginx 日志文件导入 ClickHouse 中。仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码。除了支持 HDFS 数据源之外，Seatunnel 同样支持将数据从 Kafka 中实时读取处理写入 ClickHouse 中。我们的下一篇文章将会介绍，如何将 Hive 中的数据快速导入 ClickHouse 中。</p><p>当然，Seatunnel 不仅仅是 ClickHouse 数据写入的工具，在 Elasticsearch 以及 Kafka等 数据源的写入上同样可以扮演相当重要的角色。</p><p>希望了解 Seatunnel 和 ClickHouse、Elasticsearch、Kafka 结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><p>-- Power by <a href="https://github.com/InterestingLab" target="_blank" rel="noopener noreferrer">InterestingLab</a></p>]]></content>
        <category label="HDFS" term="HDFS"/>
        <category label="ClickHouse" term="ClickHouse"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何快速地把 Hive 中的数据导入 ClickHouse]]></title>
        <id>hive-to-clickhouse</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/hive-to-clickhouse"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[ClickHouse是面向OLAP的分布式列式DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至ClickHouse这个优秀的数据仓库之中，当前日数据量达到了300亿。]]></summary>
        <content type="html"><![CDATA[<p>ClickHouse是面向OLAP的分布式列式DBMS。我们部门目前已经把所有数据分析相关的日志数据存储至ClickHouse这个优秀的数据仓库之中，当前日数据量达到了300亿。</p><p>在之前的文章 <a href="/zh-CN/blog/i18n/zh-CN/docusaurus-plugin-content-blog/current/2021-12-30-hdfs-to-clickhouse.mdtent-blog/current/2021-12-30-hdfs-to-clickhouse.md">如何快速地把HDFS中的数据导入ClickHouse</a> 中我们提到过使用 Seatunnel <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> 对HDFS中的数据经过很简单的操作就可以将数据写入ClickHouse。HDFS中的数据一般是非结构化的数据，那么针对存储在Hive中的结构化数据，我们应该怎么操作呢？</p><p><img loading="lazy" src="/zh-CN/assets/images/hive-logo-c9aedd90b5ea9668c87fe25ad92a8e6c.png" width="962" height="518"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="hive-to-clickhouse">Hive to ClickHouse<a class="hash-link" href="#hive-to-clickhouse" title="Direct link to heading">​</a></h2><p>假定我们的数据已经存储在Hive中，我们需要读取Hive表中的数据并筛选出我们关心的字段，或者对字段进行转换，最后将对应的字段写入ClickHouse的表中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="hive-schema">Hive Schema<a class="hash-link" href="#hive-schema" title="Direct link to heading">​</a></h3><p>我们在Hive中存储的数据表结构如下，存储的是很常见的Nginx日志</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE `nginx_msg_detail`(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `hostname` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `domain` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `remote_addr` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `request_time` float,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `datetime` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `url` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `status` int,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `data_size` int,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `referer` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `cookie_info` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `user_agent` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `minute` string)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> PARTITIONED BY (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `date` string,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   `hour` string)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="clickhouse-schema">ClickHouse Schema<a class="hash-link" href="#clickhouse-schema" title="Direct link to heading">​</a></h3><p>我们的ClickHouse建表语句如下，我们的表按日进行分区</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE cms.cms_msg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date Date,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    datetime DateTime,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    request_time Float32,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hostname String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remote_addr String,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    data_size Int32</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) ENGINE = MergeTree PARTITION BY date ORDER BY (date, hostname) SETTINGS index_granularity = 16384</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-with-clickhouse">Seatunnel with ClickHouse<a class="hash-link" href="#seatunnel-with-clickhouse" title="Direct link to heading">​</a></h2><p>接下来会给大家介绍，我们如何通过 Seatunnel 将Hive中的数据写入ClickHouse中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上。Seatunnel 拥有着非常丰富的插件，支持从Kafka、HDFS、Kudu中读取数据，进行各种各样的数据处理，并将结果写入ClickHouse、Elasticsearch或者Kafka中。</p><p>Seatunnel的环境准备以及安装步骤这里就不一一赘述了，具体安装步骤可以参考上一篇文章或者访问 <a href="/zh-CN/docs/introduction">Seatunnel Docs</a></p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">Seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个Seatunnel Pipeline的配置文件即可完成数据的导入。</p><p>配置文件包括四个部分，分别是Spark、Input、filter和Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是Spark的相关配置，主要配置Spark执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  // 这个配置必需填写</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.sql.catalogImplementation = "hive"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>这一部分定义数据源，如下是从Hive文件中读取text格式数据的配置案例。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hive {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from access.nginx_msg_detail"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>看，很简单的一个配置就可以从Hive中读取数据了。其中<code>pre_sql</code>是从Hive中读取数据SQL，<code>table_name</code>是将读取后的数据，注册成为Spark中临时表的表名，可为任意字段。</p><p>需要注意的是，必须保证hive的metastore是在服务状态。</p><p>在Cluster、Client、Local模式下运行时，必须把<code>hive-site.xml</code>文件置于提交任务节点的$HADOOP_CONF目录下</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>在Filter部分，这里我们配置一系列的转化，我们这里把不需要的minute和hour字段丢弃。当然我们也可以在读取Hive的时候通过<code>pre_sql</code>不读取这些字段</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remove {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = ["minute", "hour"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>最后我们将处理好的结构化数据写入ClickHouse</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        host = "your.clickhouse.host:8123"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "nginx_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields = ["date", "datetime", "hostname", "url", "http_code", "request_time", "data_size", "domain"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="running-seatunnel">Running Seatunnel<a class="hash-link" href="#running-seatunnel" title="Direct link to heading">​</a></h3><p>我们将上述四部分配置组合成为我们的配置文件<code>config/batch.conf</code>。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/batch.conf</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  // 这个配置必需填写</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.sql.catalogImplementation = "hive"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hive {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from access.nginx_msg_detail"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remove {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = ["minute", "hour"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    clickhouse {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        host = "your.clickhouse.host:8123"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        fields = ["date", "datetime", "hostname", "uri", "http_code", "request_time", "data_size", "domain"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        username = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel，即可将数据写入ClickHouse。这里我们以本地模式为例。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/start-seatunnel.sh --config config/batch.conf -e client -m 'local[2]'</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何使用 Seatunnel 将Hive中的数据导入ClickHouse中。仅仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码，十分简单。</p><p>希望了解 Seatunnel 与ClickHouse、Elasticsearch、Kafka、Hadoop结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><p>-- Power by <a href="https://github.com/InterestingLab" target="_blank" rel="noopener noreferrer">InterestingLab</a></p>]]></content>
        <category label="Hive" term="Hive"/>
        <category label="ClickHouse" term="ClickHouse"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何使用 Spark 快速将数据写入 Elasticsearch]]></title>
        <id>spark-execute-elasticsearch</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/spark-execute-elasticsearch"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[说到数据写入 Elasticsearch，最先想到的肯定是Logstash。Logstash因为其简单上手、可扩展、可伸缩等优点被广大用户接受。但是尺有所短，寸有所长，Logstash肯定也有它无法适用的应用场景，比如：]]></summary>
        <content type="html"><![CDATA[<p>说到数据写入 Elasticsearch，最先想到的肯定是Logstash。Logstash因为其简单上手、可扩展、可伸缩等优点被广大用户接受。但是尺有所短，寸有所长，Logstash肯定也有它无法适用的应用场景，比如：</p><ul><li>海量数据ETL</li><li>海量数据聚合</li><li>多源数据处理</li></ul><p>为了满足这些场景，很多同学都会选择Spark，借助Spark算子进行数据处理，最后将处理结果写入Elasticsearch。</p><p>我们部门之前利用Spark对Nginx日志进行分析，统计我们的Web服务访问情况，将Nginx日志每分钟聚合一次最后将结果写入Elasticsearch，然后利用Kibana配置实时监控Dashboard。Elasticsearch和Kibana都很方便、实用，但是随着类似需求越来越多，如何快速通过Spark将数据写入Elasticsearch成为了我们的一大问题。</p><p>今天给大家推荐一款能够实现数据快速写入的黑科技 Seatunnel <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> 一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上，简单易用，灵活配置，无需开发。</p><p><img loading="lazy" src="/zh-CN/assets/images/wd-struct-fd963482dc80fdee6e4930107709bd28.png" width="818" height="466"></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="kafka-to-elasticsearch">Kafka to Elasticsearch<a class="hash-link" href="#kafka-to-elasticsearch" title="Direct link to heading">​</a></h2><p>和Logstash一样，Seatunnel同样支持多种类型的数据输入，这里我们以最常见的Kakfa作为输入源为例，讲解如何使用 Seatunnel 将数据快速写入Elasticsearch</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="log-sample">Log Sample<a class="hash-link" href="#log-sample" title="Direct link to heading">​</a></h3><p>原始日志格式如下:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">127.0.0.1 elasticsearch.cn 114.250.140.241 0.001s "127.0.0.1:80" [26/Oct/2018:21:54:32 +0800] "GET /article HTTP/1.1" 200 123 "-" - "Dalvik/2.1.0 (Linux; U; Android 7.1.1; OPPO R11 Build/NMF26X)"</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="elasticsearch-document">Elasticsearch Document<a class="hash-link" href="#elasticsearch-document" title="Direct link to heading">​</a></h3><p>我们想要统计，一分钟每个域名的访问情况，聚合完的数据有以下字段:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">domain String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hostname String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">status int</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">datetime String</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">count int</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-with-elasticsearch">Seatunnel with Elasticsearch<a class="hash-link" href="#seatunnel-with-elasticsearch" title="Direct link to heading">​</a></h2><p>接下来会给大家详细介绍，我们如何通过 Seatunnel 读取Kafka中的数据，对数据进行解析以及聚合，最后将处理结果写入Elasticsearch中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 同样拥有着非常丰富的插件，支持从Kafka、HDFS、Hive中读取数据，进行各种各样的数据处理，并将结果写入Elasticsearch、Kudu或者Kafka中。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="prerequisites">Prerequisites<a class="hash-link" href="#prerequisites" title="Direct link to heading">​</a></h3><p>首先我们需要安装seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备Spark环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT language-yaml theme-code-block"><div class="codeBlockContent_wNvx yaml"><pre tabindex="0" class="prism-code language-yaml codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">//archive.apache.org/dist/spark/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">bin</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tar </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">xvf https</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">//archive.apache.org/dist/spark/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">bin</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">//github.com/InterestingLab/seatunnel/releases/download/v1.1.1/seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">1.1.1.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">1.1.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># 指定Spark安装路径</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SPARK_HOME=$</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">SPARK_HOME</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">/usr/local/spark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">2.2.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">bin</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">hadoop2.7</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">Seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>与Logstash一样，我们仅需要编写一个Seatunnel Pipeline的配置文件即可完成数据的导入，相信了解Logstash的朋友可以很快入手 Seatunnel 配置。</p><p>配置文件包括四个部分，分别是Spark、Input、filter和Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是Spark的相关配置，主要配置Spark执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.streaming.batchDuration = 5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>这一部分定义数据源，如下是从Kafka中读取数据的配置案例，</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    topics = "seatunnel-es"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.group.id = "seatunnel_es_group"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.rebalance.max.retries = 100</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>在Filter部分，这里我们配置一系列的转化，包括正则解析将日志进行拆分、时间转换将HTTPDATE转化为Elasticsearch支持的日期格式、对Number类型的字段进行类型转换以及通过SQL进行数据聚合</p><div class="codeBlockContainer_I0IT language-yaml theme-code-block"><div class="codeBlockContent_wNvx yaml"><pre tabindex="0" class="prism-code language-yaml codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用正则解析原始日志</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 最开始数据都在raw_message字段中</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "raw_message"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern = '%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">hostname</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">domain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">IP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">remote_addr</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NUMBER</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">request_time</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">s\\s\"%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">upstream_ip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\"\\s\\</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">HTTPDATE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">timestamp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain">\\s\"%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">method</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">url</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">http_ver</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\"\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NUMBER</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NUMBER</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">body_bytes_send</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">referer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">NOTSPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">cookie_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">\\s\"%</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">DATA</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">user_agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">'</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Elasticsearch中支持的格式</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "timestamp"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field = "datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format = "dd/MMM/yyyy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">HH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">mm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">ss Z"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format = "yyyy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">MM</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">dd'T'HH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">mm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">ss.SSS+08</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">00"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)">## 利用SQL对数据进行聚合</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select domain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> hostname</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> int(status)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> datetime</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> count(</span><span class="token important">*)</span><span class="token plain"> from access_log group by domain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> hostname</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> status</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>最后我们将处理好的结构化数据写入Elasticsearch。</p><div class="codeBlockContainer_I0IT language-yaml theme-code-block"><div class="codeBlockContent_wNvx yaml"><pre tabindex="0" class="prism-code language-yaml codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elasticsearch </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        hosts = </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"localhost:9200"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index = "seatunnel</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">$</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">now</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain">"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        es.batch.size.entries = 100000</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index_time_format = "yyyy.MM.dd"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="running-seatunnel">Running Seatunnel<a class="hash-link" href="#running-seatunnel" title="Direct link to heading">​</a></h3><p>我们将上述四部分配置组合成为我们的配置文件 <code>config/batch.conf</code>。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/batch.conf</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.streaming.batchDuration = 5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "seatunnel-es"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.group.id = "seatunnel_es_group"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.rebalance.max.retries = 100</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 使用正则解析原始日志</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 最开始数据都在raw_message字段中</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    grok {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "raw_message"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pattern = '%{IP:hostname}\\s%{NOTSPACE:domain}\\s%{IP:remote_addr}\\s%{NUMBER:request_time}s\\s\"%{DATA:upstream_ip}\"\\s\\[%{HTTPDATE:timestamp}\\]\\s\"%{NOTSPACE:method}\\s%{DATA:url}\\s%{NOTSPACE:http_ver}\"\\s%{NUMBER:status}\\s%{NUMBER:body_bytes_send}\\s%{DATA:referer}\\s%{NOTSPACE:cookie_info}\\s\"%{DATA:user_agent}'</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # 将"dd/MMM/yyyy:HH:mm:ss Z"格式的数据转换为</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Elasticsearch中支持的格式</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_field = "timestamp"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_field = "datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        source_time_format = "dd/MMM/yyyy:HH:mm:ss Z"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        target_time_format = "yyyy-MM-dd'T'HH:mm:00.SSS+08:00"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ## 利用SQL对数据进行聚合</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select domain, hostname, status, datetime, count(*) from access_log group by domain, hostname, status, datetime"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    elasticsearch {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        hosts = ["localhost:9200"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index = "seatunnel-${now}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        es.batch.size.entries = 100000</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        index_time_format = "yyyy.MM.dd"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel，即可将数据写入Elasticsearch。这里我们以本地模式为例。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/start-seatunnel.sh --config config/batch.conf -e client -m 'local[2]'</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>最后，写入Elasticsearch中的数据如下，再配上Kibana就可以实现Web服务的实时监控了^_^.</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">"_source": {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "domain": "elasticsearch.cn",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "hostname": "localhost",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "status": "200",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "datetime": "2018-11-26T21:54:00.000+08:00",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    "count": 26</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  }</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何通过 Seatunnel 将Kafka中的数据写入Elasticsearch中。仅仅通过一个配置文件便可快速运行一个Spark Application，完成数据的处理、写入，无需编写任何代码，十分简单。</p><p>当数据处理过程中有遇到Logstash无法支持的场景或者Logstah性能无法达到预期的情况下，都可以尝试使用 Seatunnel 解决问题。</p><p>希望了解 Seatunnel 与Elasticsearch、Kafka、Hadoop结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><p><strong>我们近期会再发布一篇《如何用Spark和Elasticsearch做交互式数据分析》，敬请期待.</strong></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="contract-us">Contract us<a class="hash-link" href="#contract-us" title="Direct link to heading">​</a></h2><ul><li>邮件列表 : <strong><a href="mailto:dev@seatunnel.apache.org" target="_blank" rel="noopener noreferrer">dev@seatunnel.apache.org</a></strong>. 发送任意内容至 <code>dev-subscribe@seatunnel.apache.org</code>， 按照回复订阅邮件列表。</li><li>Slack: 发送 <code>Request to join SeaTunnel slack</code> 邮件到邮件列表 (<code>dev@seatunnel.apache.org</code>), 我们会邀请你加入（在此之前请确认已经注册Slack）.</li><li><a href="https://space.bilibili.com/1542095008" target="_blank" rel="noopener noreferrer">bilibili B站 视频</a></li></ul>]]></content>
        <category label="Spark" term="Spark"/>
        <category label="Kafka" term="Kafka"/>
        <category label="Elasticsearch" term="Elasticsearch"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[怎么用 Spark 在 TiDB 上做 OLAP 分析]]></title>
        <id>spark-execute-tidb</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/spark-execute-tidb"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[TiDB 是一款定位于在线事务处理/在线分析处理的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。]]></summary>
        <content type="html"><![CDATA[<p><img src="https://download.pingcap.com/images/tidb-planet.jpg"></p><p><a href="https://github.com/pingcap/tidb" target="_blank" rel="noopener noreferrer">TiDB</a> 是一款定位于在线事务处理/在线分析处理的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。</p><p>TiSpark 是 PingCAP 为解决用户复杂 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势。</p><p>直接使用 TiSpark 完成 OLAP 操作需要了解 Spark，还需要一些开发工作。那么，有没有一些开箱即用的工具能帮我们更快速地使用 TiSpark 在 TiDB 上完成 OLAP 分析呢？</p><p>目前开源社区上有一款工具 <strong>Seatunnel</strong>，项目地址 <a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> ，可以基于Spark，在 TiSpark 的基础上快速实现 TiDB 数据读取和 OLAP 分析。</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="使用-seatunnel-操作tidb">使用 Seatunnel 操作TiDB<a class="hash-link" href="#使用-seatunnel-操作tidb" title="Direct link to heading">​</a></h2><p>在我们线上有这么一个需求，从 TiDB 中读取某一天的网站访问数据，统计每个域名以及服务返回状态码的访问次数，最后将统计结果写入 TiDB 另外一个表中。 我们来看看 Seatunnel 是如何实现这么一个功能的。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p><a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">Seatunnel</a> 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在 Spark 之上。Seatunnel 拥有着非常丰富的插件，支持从 TiDB、Kafka、HDFS、Kudu 中读取数据，进行各种各样的数据处理，然后将结果写入 TiDB、ClickHouse、Elasticsearch 或者 Kafka 中。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="准备工作">准备工作<a class="hash-link" href="#准备工作" title="Direct link to heading">​</a></h4><h5 class="anchor anchorWithStickyNavbar_mojV" id="1-tidb-表结构介绍">1. TiDB 表结构介绍<a class="hash-link" href="#1-tidb-表结构介绍" title="Direct link to heading">​</a></h5><p><strong>Input</strong>（存储访问日志的表）</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE access_log (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain VARCHAR(255),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    datetime VARCHAR(63),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    remote_addr VARCHAR(63),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    http_ver VARCHAR(15),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    body_bytes_send INT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status INT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    request_time FLOAT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    url TEXT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-----------------+--------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| Field           | Type         | Null | Key  | Default | Extra |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-----------------+--------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| domain          | varchar(255) | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| datetime        | varchar(63)  | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| remote_addr     | varchar(63)  | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| http_ver        | varchar(15)  | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| body_bytes_send | int(11)      | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| status          | int(11)      | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| request_time    | float        | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| url             | text         | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+-----------------+--------------+------+------+---------+-------+</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><strong>Output</strong>（存储结果数据的表）</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CREATE TABLE access_collect (</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    date VARCHAR(23),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    domain VARCHAR(63),</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    status INT,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    hit INT</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+-------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| Field  | Type        | Null | Key  | Default | Extra |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+-------------+------+------+---------+-------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| date   | varchar(23) | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| domain | varchar(63) | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| status | int(11)     | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| hit    | int(11)     | YES  |      | NULL    |       |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+--------+-------------+------+------+---------+-------+</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="2-安装-seatunnel">2. 安装 Seatunnel<a class="hash-link" href="#2-安装-seatunnel" title="Direct link to heading">​</a></h5><p>有了 TiDB 输入和输出表之后， 我们需要安装 Seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备 Spark环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 下载安装Spark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tar -xvf https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 下载安装seatunnel</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">https://github.com/InterestingLab/seatunnel/releases/download/v1.2.0/seatunnel-1.2.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip seatunnel-1.2.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd seatunnel-1.2.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/seatunnel-env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 指定Spark安装路径</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SPARK_HOME=${SPARK_HOME:-/usr/local/spark-2.1.0-bin-hadoop2.7}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="实现-seatunnel-处理流程">实现 Seatunnel 处理流程<a class="hash-link" href="#实现-seatunnel-处理流程" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个 Seatunnel 配置文件即可完成数据的读取、处理、写入。</p><p>Seatunnel 配置文件由四个部分组成，分别是 <code>Spark</code>、<code>Input</code>、<code>Filter</code> 和 <code>Output</code>。<code>Input</code> 部分用于指定数据的输入源，<code>Filter</code> 部分用于定义各种各样的数据处理、聚合，<code>Output</code> 部分负责将处理之后的数据写入指定的数据库或者消息队列。</p><p>整个处理流程为 <code>Input</code> -&gt; <code>Filter</code> -&gt; <code>Output</code>，整个流程组成了 Seatunnel 的 处理流程（Pipeline）。</p><blockquote><p>以下是一个具体配置，此配置来源于线上实际应用，但是为了演示有所简化。</p></blockquote><h5 class="anchor anchorWithStickyNavbar_mojV" id="input-tidb">Input (TiDB)<a class="hash-link" href="#input-tidb" title="Direct link to heading">​</a></h5><p>这里部分配置定义输入源，如下是从 TiDB 一张表中读取数据。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "nginx"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from nginx.access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_nginx_input"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h5><p>在Filter部分，这里我们配置一系列的转化, 大部分数据分析的需求，都是在Filter完成的。Seatunnel 提供了丰富的插件，足以满足各种数据分析需求。这里我们通过 SQL 插件完成数据的聚合操作。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_nginx_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)='2019-01-20' group by domain, status, substring(datetime, 1, 10)"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="output-tidb">Output (TiDB)<a class="hash-link" href="#output-tidb" title="Direct link to heading">​</a></h5><p>最后， 我们将处理后的结果写入TiDB另外一张表中。TiDB Output是通过JDBC实现的</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        url = "jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;characterEncoding=utf8"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "access_collect"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        user = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        save_mode = "append"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h5 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h5><p>这一部分是 Spark 的相关配置，主要配置 Spark 执行时所需的资源大小以及其他 Spark 配置。</p><p>我们的 TiDB Input 插件是基于 TiSpark 实现的，而 TiSpark 依赖于 TiKV 集群和 Placement Driver (PD)。因此我们需要指定 PD 节点信息以及 TiSpark 相关配置<code>spark.tispark.pd.addresses</code>和<code>spark.sql.extensions</code>。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel-tidb"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  # Set for TiSpark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.tispark.pd.addresses = "localhost:2379"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.sql.extensions = "org.apache.spark.sql.TiExtensions"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="运行-seatunnel">运行 Seatunnel<a class="hash-link" href="#运行-seatunnel" title="Direct link to heading">​</a></h4><p>我们将上述四部分配置组合成我们最终的配置文件 <code>conf/tidb.conf</code></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.app.name = "seatunnel-tidb"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    # Set for TiSpark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.tispark.pd.addresses = "localhost:2379"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    spark.sql.extensions = "org.apache.spark.sql.TiExtensions"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        database = "nginx"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        pre_sql = "select * from nginx.access_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_table"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "spark_nginx_log"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)='2019-01-20' group by domain, status, substring(datetime, 1, 10)"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tidb {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        url = "jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;characterEncoding=utf8"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table = "access_collect"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        user = "username"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        password = "password"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        save_mode = "append"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>执行命令，指定配置文件，运行 Seatunnel ，即可实现我们的数据处理逻辑。</p><ul><li>Local</li></ul><blockquote><p>./bin/start-seatunnel.sh --config config/tidb.conf --deploy-mode client --master 'local<!-- -->[2]<!-- -->'</p></blockquote><ul><li>yarn-client</li></ul><blockquote><p>./bin/start-seatunnel.sh --config config/tidb.conf --deploy-mode client --master yarn</p></blockquote><ul><li>yarn-cluster</li></ul><blockquote><p>./bin/start-seatunnel.sh --config config/tidb.conf --deploy-mode cluster -master yarn</p></blockquote><p>如果是本机测试验证逻辑，用本地模式（Local）就可以了，一般生产环境下，都是使用<code>yarn-client</code>或者<code>yarn-cluster</code>模式。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="检查结果">检查结果<a class="hash-link" href="#检查结果" title="Direct link to heading">​</a></h4><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">mysql&gt; select * from access_collect;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------------+--------+--------+------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| date       | domain | status | hit  |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------------+--------+--------+------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 2019-01-20 | b.com  |    200 |   63 |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">| 2019-01-20 | a.com  |    200 |   85 |</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">+------------+--------+--------+------+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2 rows in set (0.21 sec)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="总结">总结<a class="hash-link" href="#总结" title="Direct link to heading">​</a></h2><p>在这篇文章中，我们介绍了如何使用 Seatunnel 从 TiDB 中读取数据，做简单的数据处理之后写入 TiDB 另外一个表中。仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码。</p><p>除了支持 TiDB 数据源之外，Seatunnel 同样支持Elasticsearch, Kafka, Kudu, ClickHouse等数据源。</p><p><strong>于此同时，我们正在研发一个重要功能，就是在 Seatunnel 中，利用 TiDB 的事务特性，实现从 Kafka 到 TiDB 流式数据处理，并且支持端（Kafka）到端（TiDB）的 Exactly-Once 数据一致性。</strong></p><p>希望了解 Seatunnel 和 TiDB，ClickHouse、Elasticsearch、Kafka结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="联系我们">联系我们<a class="hash-link" href="#联系我们" title="Direct link to heading">​</a></h2><ul><li>邮件列表 : <strong><a href="mailto:dev@seatunnel.apache.org" target="_blank" rel="noopener noreferrer">dev@seatunnel.apache.org</a></strong>. 发送任意内容至 <code>dev-subscribe@seatunnel.apache.org</code>， 按照回复订阅邮件列表。</li><li>Slack: 发送 <code>Request to join SeaTunnel slack</code> 邮件到邮件列表 (<code>dev@seatunnel.apache.org</code>), 我们会邀请你加入（在此之前请确认已经注册Slack）.</li><li><a href="https://space.bilibili.com/1542095008" target="_blank" rel="noopener noreferrer">bilibili B站 视频</a></li></ul><p>-- Power by <a href="https://github.com/InterestingLab" target="_blank" rel="noopener noreferrer">InterestingLab</a></p>]]></content>
        <category label="Spark" term="Spark"/>
        <category label="TiDB" term="TiDB"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何支持的 Spark StructuredStreaming]]></title>
        <id>spark-structured-streaming</id>
        <link href="https://seatunnel.apache.org/zh-CN/blog/spark-structured-streaming"/>
        <updated>2021-12-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[前言]]></summary>
        <content type="html"><![CDATA[<h3 class="anchor anchorWithStickyNavbar_mojV" id="前言">前言<a class="hash-link" href="#前言" title="Direct link to heading">​</a></h3><p>StructuredStreaming是Spark 2.0以后新开放的一个模块，相比SparkStreaming，它有一些比较突出的优点：<br> <!-- --> <!-- --> <!-- -->一、它能做到更低的延迟;<br>
<!-- --> <!-- --> <!-- -->二、可以做实时的聚合，例如实时计算每天每个商品的销售总额；<br>
<!-- --> <!-- --> <!-- -->三、可以做流与流之间的关联，例如计算广告的点击率，需要将广告的曝光记录和点击记录关联。<br>
以上几点如果使用SparkStreaming来实现可能会比较麻烦或者说是很难实现，但是使用StructuredStreaming实现起来会比较轻松。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="如何使用structuredstreaming">如何使用StructuredStreaming<a class="hash-link" href="#如何使用structuredstreaming" title="Direct link to heading">​</a></h3><p>可能你没有详细研究过StructuredStreaming，但是发现StructuredStreaming能很好的解决你的需求，如何快速利用StructuredStreaming来解决你的需求？目前社区有一款工具 <strong>Seatunnel</strong>，项目地址：<a href="https://github.com/apache/incubator-seatunnel" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-seatunnel</a> ,
可以高效低成本的帮助你利用StructuredStreaming来完成你的需求。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel">Seatunnel<a class="hash-link" href="#seatunnel" title="Direct link to heading">​</a></h3><p>Seatunnel 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在Spark之上。Seatunnel 拥有着非常丰富的插件，支持从Kafka、HDFS、Kudu中读取数据，进行各种各样的数据处理，并将结果写入ClickHouse、Elasticsearch或者Kafka中</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="准备工作">准备工作<a class="hash-link" href="#准备工作" title="Direct link to heading">​</a></h3><p>首先我们需要安装 Seatunnel，安装十分简单，无需配置系统环境变量</p><ol><li>准备Spark环境</li><li>安装 Seatunnel</li><li>配置 Seatunnel</li></ol><p>以下是简易步骤，具体安装可以参照 <a href="/zh-CN/docs/quick-start">Quick Start</a></p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd /usr/local</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">tar -xvf https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://github.com/InterestingLab/seatunnel/releases/download/v1.3.0/seatunnel-1.3.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip seatunnel-1.3.0.zip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd seatunnel-1.3.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vim config/seatunnel-env.sh</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 指定Spark安装路径</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">SPARK_HOME=${SPARK_HOME:-/usr/local/spark-2.2.0-bin-hadoop2.7}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="seatunnel-pipeline">Seatunnel Pipeline<a class="hash-link" href="#seatunnel-pipeline" title="Direct link to heading">​</a></h3><p>我们仅需要编写一个 Seatunnel Pipeline的配置文件即可完成数据的导入。</p><p>配置文件包括四个部分，分别是Spark、Input、filter和Output。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="spark">Spark<a class="hash-link" href="#spark" title="Direct link to heading">​</a></h4><p>这一部分是Spark的相关配置，主要配置Spark执行时所需的资源大小。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h4 class="anchor anchorWithStickyNavbar_mojV" id="input">Input<a class="hash-link" href="#input" title="Direct link to heading">​</a></h4><p>下面是一个从kafka读取数据的例子</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    topics = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    schema = "{\"name\":\"string\",\"age\":\"integer\",\"addrs\":{\"country\":\"string\",\"city\":\"string\"}}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>通过上面的配置就可以读取kafka里的数据了 ，topics是要订阅的kafka的topic，同时订阅多个topic可以以逗号隔开，consumer.bootstrap.servers就是Kafka的服务器列表，schema是可选项，因为StructuredStreaming从kafka读取到的值(官方固定字段value)是binary类型的，详见<a href="http://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html" target="_blank" rel="noopener noreferrer">http://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html</a>
但是如果你确定你kafka里的数据是json字符串的话，你可以指定schema，input插件将按照你指定的schema解析</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="filter">Filter<a class="hash-link" href="#filter" title="Direct link to heading">​</a></h4><p>下面是一个简单的filter例子</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "student"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select name,age from student"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><code>table_name</code>是注册成的临时表名，以便于在下面的sql使用</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="output">Output<a class="hash-link" href="#output" title="Direct link to heading">​</a></h4><p>处理好的数据往外输出，假设我们的输出也是kafka</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafka {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topic = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        producer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        streaming_output_mode = "update"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpointLocation = "/your/path"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p><code>topic</code> 是你要输出的topic，<code> producer.bootstrap.servers</code>是kafka集群列表，<code>streaming_output_mode</code>是StructuredStreaming的一个输出模式参数，有三种类型<code>append|update|complete</code>，具体使用参见文档<a href="http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-modes" target="_blank" rel="noopener noreferrer">http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#output-modes</a></p><p><code>checkpointLocation</code>是StructuredStreaming的checkpoint路径，如果配置了的话，这个目录会存储程序的运行信息，比如程序退出再启动的话会接着上次的offset进行消费。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="场景分析">场景分析<a class="hash-link" href="#场景分析" title="Direct link to heading">​</a></h3><p>以上就是一个简单的例子，接下来我们就来介绍的稍微复杂一些的业务场景</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="场景一实时聚合场景">场景一：实时聚合场景<a class="hash-link" href="#场景一实时聚合场景" title="Direct link to heading">​</a></h4><p>假设现在有一个商城，上面有10种商品，现在需要实时求每天每种商品的销售额，甚至是求每种商品的购买人数（不要求十分精确）。
这么做的巨大的优势就是海量数据可以在实时处理的时候，完成聚合，再也不需要先将数据写入数据仓库，再跑离线的定时任务进行聚合，
操作起来还是很方便的。</p><p>kafka的数据如下</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{"good_id":"abc","price":300,"user_id":123456,"time":1553216320}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>那我们该怎么利用 Seatunnel 来完成这个需求呢，当然还是只需要配置就好了。</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">#spark里的配置根据业务需求配置</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#配置input</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "good_topic"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schema = "{\"good_id\":\"string\",\"price\":\"integer\",\"user_id\":\"Long\",\"time\":\"Long\"}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#配置filter    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #在程序做聚合的时候，内部会去存储程序从启动开始的聚合状态，久而久之会导致OOM,如果设置了watermark，程序自动的会去清理watermark之外的状态</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #这里表示使用ts字段设置watermark，界限为1天</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Watermark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        time_field = "time"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        time_type = "UNIX"              #UNIX表示时间字段为10为的时间戳，还有其他的类型详细可以查看插件文档</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        time_pattern = "yyyy-MM-dd"     #这里之所以要把ts对其到天是因为求每天的销售额，如果是求每小时的销售额可以对其到小时`yyyy-MM-dd HH`</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        delay_threshold = "1 day"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        watermark_field = "ts"          #设置watermark之后会新增一个字段，`ts`就是这个字段的名字</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #之所以要group by ts是要让watermark生效，approx_count_distinct是一个估值，并不是精确的count_distinct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "good_table_2"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select good_id,sum(price) total, approx_count_distinct(user_id) person from good_table_2 group by ts,good_id"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#接下来我们选择将结果实时输出到Kafka</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output{</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafka {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topic = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        producer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        streaming_output_mode = "update"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpointLocation = "/your/path"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>如上配置完成，启动 Seatunnel，就可以获取你想要的结果了。</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="场景二多个流关联场景">场景二：多个流关联场景<a class="hash-link" href="#场景二多个流关联场景" title="Direct link to heading">​</a></h4><p>假设你在某个平台投放了广告，现在要实时计算出每个广告的CTR(点击率)，数据分别来自两个topic，一个是广告曝光日志，一个是广告点击日志,
此时我们就需要把两个流数据关联到一起做计算，而 Seatunnel 最近也支持了此功能，让我们一起看一下该怎么做：</p><p>点击topic数据格式</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{"ad_id":"abc","click_time":1553216320,"user_id":12345}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>曝光topic数据格式</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{"ad_id":"abc","show_time":1553216220,"user_id":12345}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#F8F8F2"><span class="token plain">#spark里的配置根据业务需求配置</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.app.name = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.instances = 2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.cores = 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  spark.executor.memory = "1g"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#配置input</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">input {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "click_topic"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schema = "{\"ad_id\":\"string\",\"user_id\":\"Long\",\"click_time\":\"Long\"}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "click_table"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafkaStream {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topics = "show_topic"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        consumer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        schema = "{\"ad_id\":\"string\",\"user_id\":\"Long\",\"show_time\":\"Long\"}"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "show_table"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">filter {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #左关联右表必须设置watermark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #右关左右表必须设置watermark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    #http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#inner-joins-with-optional-watermarking</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Watermark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              source_table_name = "click_table" #这里可以指定为某个临时表添加watermark，不指定的话就是为input中的第一个</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              time_field = "time"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              time_type = "UNIX"               </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              delay_threshold = "3 hours"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              watermark_field = "ts" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">              result_table_name = "click_table_watermark" #添加完watermark之后可以注册成临时表，方便后续在sql中使用</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Watermark {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                source_table_name = "show_table" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                time_field = "time"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                time_type = "UNIX"               </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                delay_threshold = "2 hours"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                watermark_field = "ts" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                result_table_name = "show_table_watermark" </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    sql {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        table_name = "show_table_watermark"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        sql = "select a.ad_id,count(b.user_id)/count(a.user_id) ctr from show_table_watermark as a left join click_table_watermark as b on a.ad_id = b.ad_id and a.user_id = b.user_id "</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#接下来我们选择将结果实时输出到Kafka</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    kafka {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        topic = "seatunnel"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        producer.bootstrap.servers = "localhost:9092"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        streaming_output_mode = "append" #流关联只支持append模式</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        checkpointLocation = "/your/path"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">}</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>通过配置，到这里流关联的案例也完成了。</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="结语">结语<a class="hash-link" href="#结语" title="Direct link to heading">​</a></h3><p>通过配置能很快的利用StructuredStreaming做实时数据处理，但是还是需要对StructuredStreaming的一些概念了解，比如其中的watermark机制，还有程序的输出模式。</p><p>最后，Seatunnel 当然还支持spark streaming和spark 批处理。
如果你对这两个也感兴趣的话，可以阅读我们以前发布的文章《<a href="/zh-CN/blog/i18n/zh-CN/docusaurus-plugin-content-blog/current/2021-12-30-hive-to-clickhouse.mdtent-blog/current/2021-12-30-hive-to-clickhouse.md">如何快速地将Hive中的数据导入ClickHouse</a>》、
《<a href="/zh-CN/blog/i18n/zh-CN/docusaurus-plugin-content-blog/current/2021-12-30-spark-execute-tidb.mdtent-blog/current/2021-12-30-spark-execute-tidb.md">优秀的数据工程师，怎么用Spark在TiDB上做OLAP分析</a>》、
《<a href="/zh-CN/blog/i18n/zh-CN/docusaurus-plugin-content-blog/2021-12-30-spark-execute-elasticsearch.md/current/2021-12-30-spark-execute-elasticsearch.md">如何使用Spark快速将数据写入Elasticsearch</a>》</p><p>希望了解 Seatunnel 和 HBase, ClickHouse、Elasticsearch、Kafka、MySQL 等数据源结合使用的更多功能和案例，可以直接进入官网 <a href="https://seatunnel.apache.org/" target="_blank" rel="noopener noreferrer">https://seatunnel.apache.org/</a></p><h2 class="anchor anchorWithStickyNavbar_mojV" id="联系我们">联系我们<a class="hash-link" href="#联系我们" title="Direct link to heading">​</a></h2><ul><li>邮件列表 : <strong><a href="mailto:dev@seatunnel.apache.org" target="_blank" rel="noopener noreferrer">dev@seatunnel.apache.org</a></strong>. 发送任意内容至 <code>dev-subscribe@seatunnel.apache.org</code>， 按照回复订阅邮件列表。</li><li>Slack: 发送 <code>Request to join SeaTunnel slack</code> 邮件到邮件列表 (<code>dev@seatunnel.apache.org</code>), 我们会邀请你加入（在此之前请确认已经注册Slack）.</li><li><a href="https://space.bilibili.com/1542095008" target="_blank" rel="noopener noreferrer">bilibili B站 视频</a></li></ul>]]></content>
        <category label="Spark" term="Spark"/>
        <category label="StructuredStreaming" term="StructuredStreaming"/>
    </entry>
</feed>